{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOGmWt3F0QhQq04xNilxtLR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/profliuhao/CSIT599/blob/main/CSIT599_Module2_In_Class_Exercise_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CSIT 599 - Module 2 In Class Exercise"
      ],
      "metadata": {
        "id": "iheouZytLzyp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Cats vs Dogs Classification using Convolutional Neural Networks (CNN)\n",
        "\n",
        "### Exercise for Students\n",
        "\n",
        "This exercise demonstrates the power of CNNs for image classification tasks.\n",
        "\n",
        "Downloads dataset to current working directory to avoid permission issues.\n",
        "\n",
        "\n",
        "This exercise demonstrates the progression from basic CNNs to modern techniques\n",
        "in a step-by-step sequential manner:\n",
        "\n",
        "- STEP 1: Data preparation\n",
        "- STEP 2: Build and train Vanilla CNN (basic, no tricks)\n",
        "- STEP 3: Build and train Improved CNN (with modern techniques)  \n",
        "- STEP 4: Compare performance and analyze results\n",
        "\n",
        "\n",
        "You'll learn about:\n",
        "- Image preprocessing and data augmentation\n",
        "- Convolutional layers and feature maps\n",
        "- Pooling layers and dimensionality reduction\n",
        "- CNN architecture design\n",
        "- Training with callbacks and regularization\n",
        "\n",
        "Instructions:\n",
        "1. Fill in the blanks marked with \"# TODO: STUDENT FILL IN\"\n",
        "2. Run the code and observe the CNN's performance\n",
        "3. Experiment with different architectures and hyperparameters"
      ],
      "metadata": {
        "id": "pmVz30jaL03A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JV7SSv4Lqki",
        "outputId": "ab5dea60-d066-43af-edcf-a61b4be0221f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.19.0\n",
            "GPU Available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import urllib.request\n",
        "import zipfile\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STEP 1: DATA PREPARATION\n",
        "# ============================================================================\n",
        "\n",
        "def download_cats_dogs_dataset():\n",
        "    \"\"\"Download cats vs dogs dataset to current working directory.\"\"\"\n",
        "    print(\"STEP 1: DOWNLOADING CATS VS DOGS DATASET\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    current_dir = os.getcwd()\n",
        "    dataset_dir = os.path.join(current_dir, \"cats_dogs_dataset\")\n",
        "    zip_path = os.path.join(current_dir, \"cats_and_dogs.zip\")\n",
        "\n",
        "    dataset_url = \"https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\"\n",
        "\n",
        "    print(f\"Working directory: {current_dir}\")\n",
        "    print(f\"Dataset will be saved to: {dataset_dir}\")\n",
        "\n",
        "    # Check if dataset already exists\n",
        "    if os.path.exists(dataset_dir):\n",
        "        print(\"Dataset already exists locally!\")\n",
        "        train_dir = os.path.join(dataset_dir, \"train\")\n",
        "        validation_dir = os.path.join(dataset_dir, \"validation\")\n",
        "\n",
        "        if verify_dataset_structure(train_dir, validation_dir):\n",
        "            return train_dir, validation_dir\n",
        "        else:\n",
        "            print(\"Existing dataset is incomplete. Re-downloading...\")\n",
        "            import shutil\n",
        "            shutil.rmtree(dataset_dir)\n",
        "\n",
        "    try:\n",
        "        # Download the zip file\n",
        "        print(f\"Downloading from: {dataset_url}\")\n",
        "        print(\"This may take a few minutes...\")\n",
        "\n",
        "        def progress_hook(block_num, block_size, total_size):\n",
        "            downloaded = block_num * block_size\n",
        "            if total_size > 0:\n",
        "                percent = min(100, (downloaded * 100) / total_size)\n",
        "                mb_downloaded = downloaded / (1024 * 1024)\n",
        "                mb_total = total_size / (1024 * 1024)\n",
        "                print(f\"\\rProgress: {percent:.1f}% ({mb_downloaded:.1f}/{mb_total:.1f} MB)\",\n",
        "                      end='', flush=True)\n",
        "\n",
        "        urllib.request.urlretrieve(dataset_url, zip_path, reporthook=progress_hook)\n",
        "        print(f\"\\nDownload completed: {zip_path}\")\n",
        "\n",
        "        # Extract the zip file\n",
        "        print(\"Extracting dataset...\")\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(current_dir)\n",
        "\n",
        "        # Find the extracted directory\n",
        "        extracted_dir = None\n",
        "        for item in os.listdir(current_dir):\n",
        "            if os.path.isdir(item) and \"cats_and_dogs\" in item.lower():\n",
        "                extracted_dir = os.path.join(current_dir, item)\n",
        "                break\n",
        "\n",
        "        if extracted_dir:\n",
        "            if extracted_dir != dataset_dir:\n",
        "                os.rename(extracted_dir, dataset_dir)\n",
        "        else:\n",
        "            raise Exception(\"Could not find extracted dataset directory\")\n",
        "\n",
        "        # Clean up zip file\n",
        "        if os.path.exists(zip_path):\n",
        "            os.remove(zip_path)\n",
        "            print(\"Cleaned up zip file\")\n",
        "\n",
        "        train_dir = os.path.join(dataset_dir, \"train\")\n",
        "        validation_dir = os.path.join(dataset_dir, \"validation\")\n",
        "\n",
        "        if verify_dataset_structure(train_dir, validation_dir):\n",
        "            print(\"Dataset setup completed successfully!\")\n",
        "            return train_dir, validation_dir\n",
        "        else:\n",
        "            raise Exception(\"Dataset structure verification failed\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Download failed: {str(e)}\")\n",
        "        print(\"Creating minimal demo dataset...\")\n",
        "        return create_minimal_demo_dataset()\n",
        "\n",
        "def verify_dataset_structure(train_dir, validation_dir):\n",
        "    \"\"\"Verify that the dataset has the expected structure.\"\"\"\n",
        "    required_dirs = [\n",
        "        os.path.join(train_dir, 'cats'),\n",
        "        os.path.join(train_dir, 'dogs'),\n",
        "        os.path.join(validation_dir, 'cats'),\n",
        "        os.path.join(validation_dir, 'dogs')\n",
        "    ]\n",
        "\n",
        "    print(\"\\nVerifying dataset structure...\")\n",
        "    for dir_path in required_dirs:\n",
        "        if not os.path.exists(dir_path):\n",
        "            print(f\"Missing directory: {dir_path}\")\n",
        "            return False\n",
        "\n",
        "        image_files = [f for f in os.listdir(dir_path)\n",
        "                      if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "        print(f\"{len(image_files)} images in {os.path.basename(dir_path)}\")\n",
        "\n",
        "        if len(image_files) == 0:\n",
        "            print(f\"No images found in: {dir_path}\")\n",
        "            return False\n",
        "\n",
        "    return True"
      ],
      "metadata": {
        "id": "wVztRlyHMVCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: Data Preparation\n",
        "print(\"CATS vs DOGS CNN COMPARISON - SEQUENTIAL APPROACH\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "train_dir, validation_dir = download_cats_dogs_dataset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2GXMZJANKoU",
        "outputId": "f5e067f6-8a3d-4c52-a21a-02a350e60f79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CATS vs DOGS CNN COMPARISON - SEQUENTIAL APPROACH\n",
            "============================================================\n",
            "STEP 1: DOWNLOADING CATS VS DOGS DATASET\n",
            "==================================================\n",
            "Working directory: /content\n",
            "Dataset will be saved to: /content/cats_dogs_dataset\n",
            "Downloading from: https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "This may take a few minutes...\n",
            "Progress: 100.0% (65.4/65.4 MB)\n",
            "Download completed: /content/cats_and_dogs.zip\n",
            "Extracting dataset...\n",
            "Cleaned up zip file\n",
            "\n",
            "Verifying dataset structure...\n",
            "1000 images in cats\n",
            "1000 images in dogs\n",
            "500 images in cats\n",
            "500 images in dogs\n",
            "Dataset setup completed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_minimal_demo_dataset():\n",
        "    \"\"\"Create a minimal dataset with synthetic images for demonstration.\"\"\"\n",
        "    print(\"Creating minimal demo dataset with synthetic images...\")\n",
        "\n",
        "    try:\n",
        "        from PIL import Image\n",
        "        import numpy as np\n",
        "\n",
        "        dataset_dir = os.path.join(os.getcwd(), \"demo_cats_dogs\")\n",
        "        train_dir = os.path.join(dataset_dir, \"train\")\n",
        "        validation_dir = os.path.join(dataset_dir, \"validation\")\n",
        "\n",
        "        for split in ['train', 'validation']:\n",
        "            for category in ['cats', 'dogs']:\n",
        "                os.makedirs(os.path.join(dataset_dir, split, category), exist_ok=True)\n",
        "\n",
        "        def create_synthetic_image(category, size=(150, 150)):\n",
        "            \"\"\"Create a synthetic image with distinctive patterns for each class.\"\"\"\n",
        "            image = np.random.randint(50, 200, (size[0], size[1], 3), dtype=np.uint8)\n",
        "\n",
        "            if category == 'cats':\n",
        "                # Add horizontal stripes for cats\n",
        "                for i in range(0, size[0], 20):\n",
        "                    image[i:i+5, :, :] = [255, 200, 100]  # Orange stripes\n",
        "            else:  # dogs\n",
        "                # Add diagonal pattern for dogs\n",
        "                for i in range(size[0]):\n",
        "                    for j in range(size[1]):\n",
        "                        if (i + j) % 30 < 10:\n",
        "                            image[i, j, :] = [100, 150, 255]  # Blue diagonal\n",
        "\n",
        "            return Image.fromarray(image)\n",
        "\n",
        "        # Generate training images\n",
        "        print(\"Generating training images...\")\n",
        "        for category in ['cats', 'dogs']:\n",
        "            category_dir = os.path.join(train_dir, category)\n",
        "            for i in range(50):\n",
        "                img = create_synthetic_image(category)\n",
        "                img.save(os.path.join(category_dir, f'{category}_{i:03d}.jpg'))\n",
        "\n",
        "        # Generate validation images\n",
        "        print(\"Generating validation images...\")\n",
        "        for category in ['cats', 'dogs']:\n",
        "            category_dir = os.path.join(validation_dir, category)\n",
        "            for i in range(10):\n",
        "                img = create_synthetic_image(category)\n",
        "                img.save(os.path.join(category_dir, f'{category}_val_{i:03d}.jpg'))\n",
        "\n",
        "        print(f\"Demo dataset created at: {dataset_dir}\")\n",
        "        print(\"NOTE: This is synthetic data for demonstration only!\")\n",
        "\n",
        "        return train_dir, validation_dir\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to create demo dataset: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "def create_basic_data_generators(train_dir, validation_dir, img_height=150, img_width=150, batch_size=32):\n",
        "    \"\"\"\n",
        "    Create BASIC data generators with NO augmentation for vanilla CNN.\n",
        "\n",
        "    Args:\n",
        "        train_dir: Path to training data directory\n",
        "        validation_dir: Path to validation data directory\n",
        "        img_height: Target height for resized images\n",
        "        img_width: Target width for resized images\n",
        "        batch_size: Number of images per batch\n",
        "\n",
        "    Returns:\n",
        "        tuple: (train_generator, validation_generator)\n",
        "    \"\"\"\n",
        "    print(f\"\\nCreating BASIC data generators (no augmentation)...\")\n",
        "\n",
        "    # TODO: STUDENT FILL IN\n",
        "    # Create basic ImageDataGenerator for training data (ONLY rescaling, no augmentation)\n",
        "    train_datagen = ImageDataGenerator(rescale=________)  # Normalize to [0,1]\n",
        "\n",
        "    # TODO: STUDENT FILL IN\n",
        "    # Create basic ImageDataGenerator for validation data (ONLY rescaling)\n",
        "    validation_datagen = ImageDataGenerator(rescale=________)\n",
        "\n",
        "    # TODO: STUDENT FILL IN\n",
        "    # Create training data generator\n",
        "    # Use flow_from_directory with target_size=(img_height, img_width),\n",
        "    # batch_size=batch_size, class_mode='binary' (for cats vs dogs)\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(________, ________),\n",
        "        batch_size=________,\n",
        "        class_mode='________'  # 'binary' for cats vs dogs\n",
        "    )\n",
        "\n",
        "    # TODO: STUDENT FILL IN\n",
        "    # Create validation data generator\n",
        "    # Use flow_from_directory with target_size=(img_height, img_width),\n",
        "    # batch_size=batch_size, class_mode='binary' (for cats vs dogs)\n",
        "    validation_generator = validation_datagen.flow_from_directory(\n",
        "        ________,  # validation_dir\n",
        "        target_size=(________, ________),\n",
        "        batch_size=________,\n",
        "        class_mode='________'\n",
        "    )\n",
        "\n",
        "    print(f\"Classes found: {train_generator.class_indices}\")\n",
        "    print(f\"Training samples: {train_generator.samples}\")\n",
        "    print(f\"Validation samples: {validation_generator.samples}\")\n",
        "\n",
        "    return train_generator, validation_generator\n",
        "\n",
        "def visualize_sample_images(train_generator, title=\"Sample Images\"):\n",
        "    \"\"\"Display a batch of training images to understand the data.\"\"\"\n",
        "    print(f\"Displaying {title.lower()}...\")\n",
        "\n",
        "    sample_batch = next(train_generator)\n",
        "    images, labels = sample_batch\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    for i in range(min(8, len(images))):\n",
        "        plt.subplot(2, 4, i + 1)\n",
        "        plt.imshow(images[i])\n",
        "        label_name = 'Dog' if labels[i] == 1 else 'Cat'\n",
        "        plt.title(f'Label: {label_name}')\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.suptitle(title)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "HaJguNoLM0OE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Create basic data generators for vanilla CNN\n",
        "train_gen_basic, val_gen_basic = create_basic_data_generators(train_dir, validation_dir)\n",
        "visualize_sample_images(train_gen_basic, \"Basic Training Images (No Augmentation)\")\n",
        "\n"
      ],
      "metadata": {
        "id": "QivQnknQNH-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STEP 2: BUILD AND TRAIN VANILLA CNN\n",
        "# ============================================================================\n",
        "\n",
        "def create_vanilla_cnn(img_height=150, img_width=150):\n",
        "    \"\"\"\n",
        "    Create a VANILLA CNN model - just the basic building blocks!\n",
        "\n",
        "    This is a pure CNN without any modern tricks:\n",
        "    - NO dropout\n",
        "    - NO batch normalization\n",
        "    - NO advanced optimizations\n",
        "    - Just Conv2D + MaxPooling + Dense layers\n",
        "\n",
        "    Args:\n",
        "        img_height: Input image height\n",
        "        img_width: Input image width\n",
        "\n",
        "    Returns:\n",
        "        keras.Model: Compiled vanilla CNN model\n",
        "    \"\"\"\n",
        "    print(\"\\nSTEP 2: BUILDING VANILLA CNN\")\n",
        "    print(\"=\"*50)\n",
        "    print(\"Creating basic CNN with NO modern tricks!\")\n",
        "\n",
        "    model = keras.Sequential(name=\"Vanilla_CNN\")\n",
        "\n",
        "    # TODO: STUDENT FILL IN\n",
        "    # First Convolutional Block\n",
        "    # Add Conv2D layer: 32 filters, (3,3) kernel, 'relu' activation\n",
        "    # Specify input_shape=(img_height, img_width, 3) for RGB images\n",
        "    model.add(layers.Conv2D(\n",
        "        filters=________,\n",
        "        kernel_size=(________, ________),\n",
        "        activation='________',\n",
        "        input_shape=(________, ________, ________),\n",
        "        name='conv2d_1'\n",
        "    ))\n",
        "\n",
        "    # TODO: STUDENT FILL IN\n",
        "    # Add MaxPooling2D layer with (2,2) pool size\n",
        "    model.add(layers.MaxPooling2D(pool_size=(________, ________), name='maxpool_1'))\n",
        "\n",
        "    # TODO: STUDENT FILL IN\n",
        "    # Second Convolutional Block\n",
        "    # Add Conv2D layer: 64 filters, (3,3) kernel, 'relu' activation\n",
        "    model.add(layers.Conv2D(\n",
        "        filters=________,\n",
        "        kernel_size=(________, ________),\n",
        "        activation='________',\n",
        "        name='conv2d_2'\n",
        "    ))\n",
        "    model.add(layers.MaxPooling2D(pool_size=(________, ________), name='maxpool_2'))\n",
        "\n",
        "    # TODO: STUDENT FILL IN\n",
        "    # Third Convolutional Block\n",
        "    # Add Conv2D layer: 128 filters, (3,3) kernel, 'relu' activation\n",
        "    model.add(layers.Conv2D(\n",
        "        filters=________,\n",
        "        kernel_size=(________, ________),\n",
        "        activation='________',\n",
        "        name='conv2d_3'\n",
        "    ))\n",
        "    model.add(layers.MaxPooling2D(pool_size=(________, ________), name='maxpool_3'))\n",
        "\n",
        "    # TODO: STUDENT FILL IN\n",
        "    # Flatten the 3D feature maps to 1D for dense layers\n",
        "    # This converts from spatial features to a vector\n",
        "    model.add(layers.Flatten(name='flatten'))\n",
        "\n",
        "    # TODO: STUDENT FILL IN\n",
        "    # Add Dense layer with 512 units and 'relu' activation\n",
        "    # This learns combinations of the extracted features\n",
        "    model.add(layers.Dense(units=________, activation='________', name='dense_1'))\n",
        "\n",
        "    # TODO: STUDENT FILL IN\n",
        "    # Output layer: 1 unit with 'sigmoid' activation for binary classification\n",
        "    # Sigmoid outputs probability between 0 and 1\n",
        "    model.add(layers.Dense(units=________, activation='________', name='output'))\n",
        "\n",
        "    # TODO: STUDENT FILL IN\n",
        "    # Compile model: optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']\n",
        "    # Adam: adaptive learning rate optimizer\n",
        "    # Binary crossentropy: loss function for binary classification\n",
        "    model.compile(\n",
        "        optimizer='________',\n",
        "        loss='________',\n",
        "        metrics=['________']\n",
        "    )\n",
        "\n",
        "    print(\"\\nVanilla CNN Architecture:\")\n",
        "    model.summary()\n",
        "    print(\"Notice: NO dropout, NO batch normalization!\")\n",
        "\n",
        "    return model\n",
        "\n",
        "def train_vanilla_cnn(model, train_generator, validation_generator, epochs=10):\n",
        "    \"\"\"Train vanilla CNN with basic training (no callbacks).\"\"\"\n",
        "    print(f\"\\nTraining {model.name} (basic training, no callbacks)...\")\n",
        "\n",
        "    steps_per_epoch = int(np.ceil(train_generator.samples / train_generator.batch_size))\n",
        "    validation_steps = int(np.ceil(validation_generator.samples / validation_generator.batch_size))\n",
        "\n",
        "    print(f\"Epochs: {epochs}\")\n",
        "    print(f\"Steps per epoch: {steps_per_epoch}\")\n",
        "    print(f\"Validation steps: {validation_steps}\")\n",
        "\n",
        "    # Basic training - no callbacks\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=steps_per_epoch,\n",
        "        epochs=epochs,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=validation_steps,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    print(\"Vanilla CNN training completed!\")\n",
        "    return history\n",
        "\n",
        "def evaluate_vanilla_cnn(model, validation_generator):\n",
        "    \"\"\"Evaluate vanilla CNN performance.\"\"\"\n",
        "    print(f\"\\nEvaluating {model.name}...\")\n",
        "\n",
        "    validation_generator.reset()\n",
        "    test_loss, test_accuracy = model.evaluate(validation_generator, verbose=0)\n",
        "\n",
        "    print(f\"Vanilla CNN Results:\")\n",
        "    print(f\"  Test Loss: {test_loss:.4f}\")\n",
        "    print(f\"  Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
        "\n",
        "    # Get predictions for later comparison\n",
        "    validation_generator.reset()\n",
        "    predictions = model.predict(validation_generator, verbose=0)\n",
        "    true_labels = validation_generator.classes\n",
        "    pred_labels = (predictions > 0.5).astype(int).flatten()\n",
        "\n",
        "    return test_accuracy, pred_labels, true_labels, test_loss\n",
        "\n",
        "def plot_vanilla_training(history):\n",
        "    \"\"\"Plot vanilla CNN training history.\"\"\"\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    # Accuracy\n",
        "    ax1.plot(history.history['accuracy'], label='Training Accuracy', marker='o')\n",
        "    ax1.plot(history.history['val_accuracy'], label='Validation Accuracy', marker='s')\n",
        "    ax1.set_title('Vanilla CNN - Training History')\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Accuracy')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True)\n",
        "\n",
        "    # Loss\n",
        "    ax2.plot(history.history['loss'], label='Training Loss', marker='o')\n",
        "    ax2.plot(history.history['val_loss'], label='Validation Loss', marker='s')\n",
        "    ax2.set_title('Vanilla CNN - Loss History')\n",
        "    ax2.set_xlabel('Epoch')\n",
        "    ax2.set_ylabel('Loss')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "JiH8OQQcM42p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 2: Build and Train Vanilla CNN\n",
        "vanilla_cnn = create_vanilla_cnn(150, 150)\n",
        "history_vanilla = train_vanilla_cnn(vanilla_cnn, train_gen_basic, val_gen_basic, epochs=20)\n",
        "acc_vanilla, pred_vanilla, true_vanilla, loss_vanilla = evaluate_vanilla_cnn(vanilla_cnn, val_gen_basic)\n",
        "plot_vanilla_training(history_vanilla)"
      ],
      "metadata": {
        "id": "Y5M3fEi1NPNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================================================\n",
        "# STEP 3: BUILD AND TRAIN IMPROVED CNN\n",
        "# ============================================================================\n",
        "\n",
        "def create_augmented_data_generators(train_dir, validation_dir, img_height=150, img_width=150, batch_size=32):\n",
        "    \"\"\"Create data generators WITH augmentation for improved CNN.\"\"\"\n",
        "    print(f\"\\nSTEP 3: CREATING AUGMENTED DATA GENERATORS\")\n",
        "    print(\"=\"*50)\n",
        "    print(\"Now with data augmentation for better generalization!\")\n",
        "\n",
        "    # Advanced training data generator with augmentation\n",
        "    # Create ImageDataGenerator for training data with augmentation\n",
        "    # Include: rescale=1./255 (normalize), rotation_range=20, width_shift_range=0.2,\n",
        "    # height_shift_range=0.2, shear_range=0.2, zoom_range=0.2, horizontal_flip=True\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=________,           # Normalize pixel values to [0,1]\n",
        "        rotation_range=________,    # Randomly rotate images up to 20 degrees\n",
        "        width_shift_range=________,  # Randomly shift images horizontally by 20%\n",
        "        height_shift_range=________, # Randomly shift images vertically by 20%\n",
        "        shear_range=________,       # Randomly apply shear transformations\n",
        "        zoom_range=________,        # Randomly zoom in/out by 20%\n",
        "        horizontal_flip=________,   # Randomly flip images horizontally\n",
        "        fill_mode='nearest'         # Fill in newly created pixels\n",
        "    )\n",
        "\n",
        "    # Validation data generator (only rescaling)\n",
        "    validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    # Create generators\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(img_height, img_width),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary'\n",
        "    )\n",
        "\n",
        "    validation_generator = validation_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(img_height, img_width),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary'\n",
        "    )\n",
        "\n",
        "    print(f\"Training samples: {train_generator.samples}\")\n",
        "    print(f\"Validation samples: {validation_generator.samples}\")\n",
        "    print(\"Data augmentation includes: rotation, shifts, shear, zoom, flip\")\n",
        "\n",
        "    return train_generator, validation_generator\n",
        "\n",
        "def create_improved_cnn(img_height=150, img_width=150):\n",
        "    \"\"\"\n",
        "    Create an IMPROVED CNN model with modern techniques.\n",
        "\n",
        "    Modern improvements:\n",
        "    ✅ Batch normalization\n",
        "    ✅ Dropout regularization\n",
        "    ✅ More layers for better feature extraction\n",
        "\n",
        "    Args:\n",
        "        img_height: Input image height\n",
        "        img_width: Input image width\n",
        "\n",
        "    Returns:\n",
        "        keras.Model: Compiled improved CNN model\n",
        "    \"\"\"\n",
        "    print(\"\\nBuilding IMPROVED CNN with modern techniques!\")\n",
        "\n",
        "    model = keras.Sequential(name=\"Improved_CNN\")\n",
        "\n",
        "    # First Block with Batch Normalization\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
        "                           input_shape=(img_height, img_width, 3), name='conv2d_1'))\n",
        "    model.add(layers.BatchNormalization(name='bn_1'))  # ← NEW: Batch normalization\n",
        "    model.add(layers.MaxPooling2D((2, 2), name='maxpool_1'))\n",
        "\n",
        "    # Second Block with Batch Normalization\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu', name='conv2d_2'))\n",
        "    model.add(layers.BatchNormalization(name='bn_2'))  # ← NEW: Batch normalization\n",
        "    model.add(layers.MaxPooling2D((2, 2), name='maxpool_2'))\n",
        "\n",
        "    # Third Block with Batch Normalization\n",
        "    model.add(layers.Conv2D(128, (3, 3), activation='relu', name='conv2d_3'))\n",
        "    model.add(layers.BatchNormalization(name='bn_3'))  # ← NEW: Batch normalization\n",
        "    model.add(layers.MaxPooling2D((2, 2), name='maxpool_3'))\n",
        "\n",
        "    # Fourth Block - More depth\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu', name='conv2d_4'))\n",
        "    # model.add(layers.BatchNormalization(name='bn_4'))  # ← NEW: Batch normalization\n",
        "    model.add(layers.MaxPooling2D((2, 2), name='maxpool_4'))\n",
        "\n",
        "    # Dense layers with Dropout\n",
        "    model.add(layers.Flatten(name='flatten'))\n",
        "    model.add(layers.Dense(512, activation='relu', name='dense_1'))\n",
        "    model.add(layers.Dropout(0.2, name='dropout_1'))  # ← NEW: Dropout\n",
        "    # model.add(layers.Dense(256, activation='relu', name='dense_2'))\n",
        "    # model.add(layers.Dropout(0.2, name='dropout_2'))  # ← NEW: Dropout\n",
        "    model.add(layers.Dense(1, activation='sigmoid', name='output'))\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    print(\"\\nImproved CNN Architecture:\")\n",
        "    model.summary()\n",
        "    print(\"Notice: WITH batch normalization, dropout, and more layers!\")\n",
        "\n",
        "    return model\n",
        "\n",
        "def train_improved_cnn(model, train_generator, validation_generator, epochs=10):\n",
        "    \"\"\"Train improved CNN with advanced callbacks.\"\"\"\n",
        "    print(f\"\\nTraining {model.name} with advanced techniques...\")\n",
        "\n",
        "    # TODO: STUDENT FILL IN\n",
        "    # Define advanced callbacks for better training\n",
        "    # EarlyStopping: monitor='val_loss', patience=10, restore_best_weights=True\n",
        "    # ReduceLROnPlateau: monitor='val_loss', factor=0.2, patience=5\n",
        "    callbacks = [\n",
        "        keras.callbacks.EarlyStopping(\n",
        "            monitor='________',        # 'val_loss'\n",
        "            patience=________,         # 10\n",
        "            restore_best_weights=________  # True\n",
        "        ),\n",
        "        keras.callbacks.ReduceLROnPlateau(\n",
        "            monitor='________',        # 'val_loss'\n",
        "            factor=________,           # 0.2\n",
        "            patience=________          # 5\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    steps_per_epoch = int(np.ceil(train_generator.samples / train_generator.batch_size))\n",
        "    validation_steps = int(np.ceil(validation_generator.samples / validation_generator.batch_size))\n",
        "\n",
        "    print(f\"Max epochs: {epochs}\")\n",
        "    print(f\"Steps per epoch: {steps_per_epoch}\")\n",
        "    print(f\"Validation steps: {validation_steps}\")\n",
        "    print(\"Using callbacks: EarlyStopping + ReduceLROnPlateau\")\n",
        "\n",
        "    # Advanced training with callbacks\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=steps_per_epoch,\n",
        "        epochs=epochs,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=validation_steps,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    print(\"Improved CNN training completed!\")\n",
        "    return history\n",
        "\n",
        "def evaluate_improved_cnn(model, validation_generator):\n",
        "    \"\"\"Evaluate improved CNN performance.\"\"\"\n",
        "    print(f\"\\nEvaluating {model.name}...\")\n",
        "\n",
        "    validation_generator.reset()\n",
        "    test_loss, test_accuracy = model.evaluate(validation_generator, verbose=0)\n",
        "\n",
        "    print(f\"Improved CNN Results:\")\n",
        "    print(f\"  Test Loss: {test_loss:.4f}\")\n",
        "    print(f\"  Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
        "\n",
        "    # Get predictions for comparison\n",
        "    validation_generator.reset()\n",
        "    predictions = model.predict(validation_generator, verbose=0)\n",
        "    true_labels = validation_generator.classes\n",
        "    pred_labels = (predictions > 0.5).astype(int).flatten()\n",
        "\n",
        "    return test_accuracy, pred_labels, true_labels, test_loss\n",
        "\n",
        "def plot_improved_training(history):\n",
        "    \"\"\"Plot improved CNN training history.\"\"\"\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    # Accuracy\n",
        "    ax1.plot(history.history['accuracy'], label='Training Accuracy', marker='o')\n",
        "    ax1.plot(history.history['val_accuracy'], label='Validation Accuracy', marker='s')\n",
        "    ax1.set_title('Improved CNN - Training History')\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Accuracy')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True)\n",
        "\n",
        "    # Loss\n",
        "    ax2.plot(history.history['loss'], label='Training Loss', marker='o')\n",
        "    ax2.plot(history.history['val_loss'], label='Validation Loss', marker='s')\n",
        "    ax2.set_title('Improved CNN - Loss History')\n",
        "    ax2.set_xlabel('Epoch')\n",
        "    ax2.set_ylabel('Loss')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "4G0Yd-S0MJni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 3: Build and Train Improved CNN\n",
        "train_gen_aug, val_gen_aug = create_augmented_data_generators(train_dir, validation_dir)\n",
        "visualize_sample_images(train_gen_aug, \"Augmented Training Images (With Data Aug)\")\n",
        "\n",
        "improved_cnn = create_improved_cnn(150, 150)\n",
        "history_improved = train_improved_cnn(improved_cnn, train_gen_aug, val_gen_aug, epochs=20)\n",
        "acc_improved, pred_improved, true_improved, loss_improved = evaluate_improved_cnn(improved_cnn, val_gen_aug)\n",
        "plot_improved_training(history_improved)"
      ],
      "metadata": {
        "id": "IzfB4clANmaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STEP 4: COMPARE MODELS AND ANALYZE RESULTS\n",
        "# ============================================================================\n",
        "\n",
        "def compare_models(vanilla_acc, vanilla_loss, improved_acc, improved_loss):\n",
        "    \"\"\"Compare the performance of both models.\"\"\"\n",
        "    print(\"\\nSTEP 4: MODEL COMPARISON AND ANALYSIS\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    print(\"🔍 PERFORMANCE COMPARISON:\")\n",
        "    print(f\"Vanilla CNN:   {vanilla_acc:.4f} ({vanilla_acc*100:.2f}%) - Loss: {vanilla_loss:.4f}\")\n",
        "    print(f\"Improved CNN:  {improved_acc:.4f} ({improved_acc*100:.2f}%) - Loss: {improved_loss:.4f}\")\n",
        "\n",
        "    if improved_acc > vanilla_acc:\n",
        "        improvement = ((improved_acc - vanilla_acc) / vanilla_acc) * 100\n",
        "        print(f\"📈 Accuracy Improvement: {improvement:.2f}% better!\")\n",
        "\n",
        "    if improved_loss < vanilla_loss:\n",
        "        loss_improvement = ((vanilla_loss - improved_loss) / vanilla_loss) * 100\n",
        "        print(f\"📉 Loss Improvement: {loss_improvement:.2f}% better!\")\n",
        "\n",
        "def plot_model_comparison(history_vanilla, history_improved):\n",
        "    \"\"\"Plot side-by-side comparison of both models.\"\"\"\n",
        "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "    # Training accuracy\n",
        "    ax1.plot(history_vanilla.history['accuracy'], label='Vanilla CNN', marker='o', color='red')\n",
        "    ax1.plot(history_improved.history['accuracy'], label='Improved CNN', marker='s', color='blue')\n",
        "    ax1.set_title('Training Accuracy Comparison')\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Accuracy')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True)\n",
        "\n",
        "    # Validation accuracy\n",
        "    ax2.plot(history_vanilla.history['val_accuracy'], label='Vanilla CNN', marker='o', color='red')\n",
        "    ax2.plot(history_improved.history['val_accuracy'], label='Improved CNN', marker='s', color='blue')\n",
        "    ax2.set_title('Validation Accuracy Comparison')\n",
        "    ax2.set_xlabel('Epoch')\n",
        "    ax2.set_ylabel('Accuracy')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True)\n",
        "\n",
        "    # Training loss\n",
        "    ax3.plot(history_vanilla.history['loss'], label='Vanilla CNN', marker='o', color='red')\n",
        "    ax3.plot(history_improved.history['loss'], label='Improved CNN', marker='s', color='blue')\n",
        "    ax3.set_title('Training Loss Comparison')\n",
        "    ax3.set_xlabel('Epoch')\n",
        "    ax3.set_ylabel('Loss')\n",
        "    ax3.legend()\n",
        "    ax3.grid(True)\n",
        "\n",
        "    # Validation loss\n",
        "    ax4.plot(history_vanilla.history['val_loss'], label='Vanilla CNN', marker='o', color='red')\n",
        "    ax4.plot(history_improved.history['val_loss'], label='Improved CNN', marker='s', color='blue')\n",
        "    ax4.set_title('Validation Loss Comparison')\n",
        "    ax4.set_xlabel('Epoch')\n",
        "    ax4.set_ylabel('Loss')\n",
        "    ax4.legend()\n",
        "    ax4.grid(True)\n",
        "\n",
        "    plt.suptitle('Vanilla CNN vs Improved CNN - Complete Comparison', fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_confusion_matrices(y_true_vanilla, y_pred_vanilla, y_true_improved, y_pred_improved):\n",
        "    \"\"\"Plot confusion matrices for both models.\"\"\"\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "    # Vanilla CNN Confusion Matrix\n",
        "    cm_vanilla = confusion_matrix(y_true_vanilla, y_pred_vanilla)\n",
        "    sns.heatmap(cm_vanilla, annot=True, fmt='d', cmap='Reds', ax=ax1,\n",
        "                xticklabels=['Cat', 'Dog'], yticklabels=['Cat', 'Dog'])\n",
        "    ax1.set_title('Vanilla CNN\\nConfusion Matrix')\n",
        "    ax1.set_xlabel('Predicted Label')\n",
        "    ax1.set_ylabel('True Label')\n",
        "\n",
        "    # Improved CNN Confusion Matrix\n",
        "    cm_improved = confusion_matrix(y_true_improved, y_pred_improved)\n",
        "    sns.heatmap(cm_improved, annot=True, fmt='d', cmap='Blues', ax=ax2,\n",
        "                xticklabels=['Cat', 'Dog'], yticklabels=['Cat', 'Dog'])\n",
        "    ax2.set_title('Improved CNN\\nConfusion Matrix')\n",
        "    ax2.set_xlabel('Predicted Label')\n",
        "    ax2.set_ylabel('True Label')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def analyze_key_differences(vanilla_model, improved_model):\n",
        "    \"\"\"Analyze the key architectural and training differences.\"\"\"\n",
        "    print(\"\\n🛠️ KEY DIFFERENCES ANALYSIS:\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    print(\"VANILLA CNN:\")\n",
        "    print(\"  ❌ Basic Conv2D + MaxPool + Dense\")\n",
        "    print(\"  ❌ No regularization techniques\")\n",
        "    print(\"  ❌ No data augmentation\")\n",
        "    print(\"  ❌ Basic training (no callbacks)\")\n",
        "    print(\"  ❌ Likely to overfit quickly\")\n",
        "\n",
        "    print(\"\\nIMPROVED CNN:\")\n",
        "    print(\"  ✅ Batch normalization after each conv layer\")\n",
        "    print(\"  ✅ Dropout regularization in dense layers\")\n",
        "    print(\"  ✅ Data augmentation (rotation, shifts, flips)\")\n",
        "    print(\"  ✅ Advanced training callbacks\")\n",
        "    print(\"  ✅ Better generalization\")\n",
        "\n",
        "    print(f\"\\n📊 MODEL COMPLEXITY:\")\n",
        "    print(f\"Vanilla CNN Parameters:   {vanilla_model.count_params():,}\")\n",
        "    print(f\"Improved CNN Parameters:  {improved_model.count_params():,}\")\n",
        "\n",
        "def save_models(vanilla_model, improved_model):\n",
        "    \"\"\"Save both models to disk.\"\"\"\n",
        "    vanilla_model.save(\"vanilla_cnn_model.h5\")\n",
        "    improved_model.save(\"improved_cnn_model.h5\")\n",
        "    print(\"\\n💾 Models saved:\")\n",
        "    print(\"  - vanilla_cnn_model.h5\")\n",
        "    print(\"  - improved_cnn_model.h5\")\n",
        "\n"
      ],
      "metadata": {
        "id": "D_Cp5YpNNWGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# STEP 4: Compare and Analyze\n",
        "compare_models(acc_vanilla, loss_vanilla, acc_improved, loss_improved)\n",
        "plot_model_comparison(history_vanilla, history_improved)\n",
        "plot_confusion_matrices(true_vanilla, pred_vanilla, true_improved, pred_improved)\n",
        "analyze_key_differences(vanilla_cnn, improved_cnn)\n",
        "save_models(vanilla_cnn, improved_cnn)\n",
        "\n",
        "print(\"\\n🎉 EXERCISE COMPLETED!\")\n",
        "print(\"You've successfully compared vanilla CNN vs improved CNN approaches.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ziSLtPLxNxmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🎓 LEARNING SUMMARY:\n",
        "\n",
        "WHAT YOU'VE LEARNED:\n",
        "1. Basic CNN architecture (vanilla approach)\n",
        "2. Impact of modern techniques:\n",
        "   - Batch normalization → Training stability\n",
        "   - Dropout → Overfitting prevention  \n",
        "   - Data augmentation → Better generalization\n",
        "   - Advanced callbacks → Training optimization\n",
        "\n",
        "EXPECTED RESULTS:\n",
        "- Vanilla CNN: ~65-75% accuracy (may overfit)\n",
        "- Improved CNN: ~75-85% accuracy (better generalization)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "g62k8NuRNzWe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DISCUSSION QUESTIONS FOR STUDENTS\n",
        "\n",
        "1. Why are CNNs better suited for image classification compared to regular dense networks?\n",
        "   Hint: Think about spatial relationships and parameter sharing\n",
        "\n",
        "2. What is the purpose of each layer type:\n",
        "   - Convolutional layers: Feature extraction with learnable filters\n",
        "   - Pooling layers: Dimensionality reduction and translation invariance\n",
        "   - Dropout layers: Regularization to prevent overfitting\n",
        "   - Batch normalization: Stabilize training and improve convergence\n",
        "\n",
        "3. How does data augmentation help improve model performance?\n",
        "   Hint: Think about dataset size and model generalization\n",
        "\n",
        "4. What happens to the spatial dimensions as data flows through the CNN?\n",
        "   Hint: Track the output shape after each layer\n",
        "\n",
        "5. Why do we use different numbers of filters in different layers?\n",
        "   Hint: Think about feature hierarchy (simple → complex)\n",
        "\n",
        "6. How do early stopping and learning rate reduction help during training?\n",
        "   Hint: Think about overfitting and optimization\n",
        "\n",
        "7. Experiment: Try different architectures. What happens if you:\n",
        "   - Remove pooling layers?\n",
        "   - Use different filter sizes (5x5 instead of 3x3)?\n",
        "   - Add more/fewer layers?\n",
        "   - Change the number of filters?\n",
        "\n",
        "8. What are the trade-offs between model complexity and performance?\n",
        "   Hint: Consider training time, memory usage, and accuracy\n",
        "\n",
        "TROUBLESHOOTING:\n",
        "- If download fails, the code will create synthetic demo images\n",
        "- All files are saved to current directory (no permission issues)\n",
        "- Required packages: pip install tensorflow pillow scikit-learn matplotlib seaborn\n",
        "\n",
        "EXPECTED RESULTS:\n",
        "- Simple CNN: ~65-75% accuracy\n",
        "- Improved CNN: ~75-85% accuracy  \n",
        "- Training should complete in 5-15 minutes depending on hardware\n"
      ],
      "metadata": {
        "id": "6xaxD8NUmOIF"
      }
    }
  ]
}
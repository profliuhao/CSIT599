{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPO9VxCS5/3hI/Bq/YwLMzd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/profliuhao/CSIT599/blob/main/CSIT599_Module2_In_Class_Exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CSIT 599 - Module 2 In Class Exercise"
      ],
      "metadata": {
        "id": "MyttqVoZbO72"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Cats vs Dogs Classification using Convolutional Neural Networks (CNN)\n",
        "\n",
        "### Exercise for Students\n",
        "\n",
        "This exercise demonstrates the power of CNNs for image classification tasks.\n",
        "\n",
        "Downloads dataset to current working directory to avoid permission issues.\n",
        "\n",
        "You'll learn about:\n",
        "- Image preprocessing and data augmentation\n",
        "- Convolutional layers and feature maps\n",
        "- Pooling layers and dimensionality reduction\n",
        "- CNN architecture design\n",
        "- Training with callbacks and regularization\n",
        "\n",
        "Instructions:\n",
        "1. Fill in the blanks marked with \"# TODO: STUDENT FILL IN\"\n",
        "2. Run the code and observe the CNN's performance\n",
        "3. Experiment with different architectures and hyperparameters"
      ],
      "metadata": {
        "id": "E_jOSacsM5XS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Dataset: Automatically downloads cats vs dogs sample dataset to current directory\n",
        "\"\"\"\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import urllib.request\n",
        "import zipfile\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aA915z5UM4Vy",
        "outputId": "f772e045-3e0d-410a-f250-6f4d9b02f391"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.19.0\n",
            "GPU Available: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaF5gsYrMz3t"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# PART 1: LOCAL DATA DOWNLOAD AND PREPROCESSING\n",
        "# ============================================================================\n",
        "\n",
        "def download_cats_dogs_dataset():\n",
        "    \"\"\"\n",
        "    Download cats vs dogs dataset to current working directory.\n",
        "    This avoids permission issues with system directories.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (train_dir, validation_dir) paths\n",
        "    \"\"\"\n",
        "    print(\"Downloading cats vs dogs dataset to current directory...\")\n",
        "\n",
        "    # Use current working directory - no permission issues!\n",
        "    current_dir = os.getcwd()\n",
        "    dataset_dir = os.path.join(current_dir, \"cats_dogs_dataset\")\n",
        "    zip_path = os.path.join(current_dir, \"cats_and_dogs.zip\")\n",
        "\n",
        "    # Dataset URL\n",
        "    dataset_url = \"https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\"\n",
        "\n",
        "    print(f\"Working directory: {current_dir}\")\n",
        "    print(f\"Dataset will be saved to: {dataset_dir}\")\n",
        "\n",
        "    # Check if dataset already exists\n",
        "    if os.path.exists(dataset_dir):\n",
        "        print(\"Dataset already exists locally!\")\n",
        "        train_dir = os.path.join(dataset_dir, \"train\")\n",
        "        validation_dir = os.path.join(dataset_dir, \"validation\")\n",
        "\n",
        "        if verify_dataset_structure(train_dir, validation_dir):\n",
        "            return train_dir, validation_dir\n",
        "        else:\n",
        "            print(\"Existing dataset is incomplete. Re-downloading...\")\n",
        "            import shutil\n",
        "            shutil.rmtree(dataset_dir)\n",
        "\n",
        "    try:\n",
        "        # Download the zip file\n",
        "        print(f\"Downloading from: {dataset_url}\")\n",
        "        print(\"This may take a few minutes...\")\n",
        "\n",
        "        def progress_hook(block_num, block_size, total_size):\n",
        "            downloaded = block_num * block_size\n",
        "            if total_size > 0:\n",
        "                percent = min(100, (downloaded * 100) / total_size)\n",
        "                mb_downloaded = downloaded / (1024 * 1024)\n",
        "                mb_total = total_size / (1024 * 1024)\n",
        "                print(f\"\\rProgress: {percent:.1f}% ({mb_downloaded:.1f}/{mb_total:.1f} MB)\",\n",
        "                      end='', flush=True)\n",
        "\n",
        "        urllib.request.urlretrieve(dataset_url, zip_path, reporthook=progress_hook)\n",
        "        print(f\"\\nDownload completed: {zip_path}\")\n",
        "\n",
        "        # Extract the zip file\n",
        "        print(\"Extracting dataset...\")\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(current_dir)\n",
        "\n",
        "        # Find the extracted directory\n",
        "        extracted_dir = None\n",
        "        for item in os.listdir(current_dir):\n",
        "            if os.path.isdir(item) and \"cats_and_dogs\" in item.lower():\n",
        "                extracted_dir = os.path.join(current_dir, item)\n",
        "                break\n",
        "\n",
        "        if extracted_dir:\n",
        "            # Rename to standard name\n",
        "            if extracted_dir != dataset_dir:\n",
        "                os.rename(extracted_dir, dataset_dir)\n",
        "        else:\n",
        "            raise Exception(\"Could not find extracted dataset directory\")\n",
        "\n",
        "        # Clean up zip file\n",
        "        if os.path.exists(zip_path):\n",
        "            os.remove(zip_path)\n",
        "            print(\"Cleaned up zip file\")\n",
        "\n",
        "        # Set up directory paths\n",
        "        train_dir = os.path.join(dataset_dir, \"train\")\n",
        "        validation_dir = os.path.join(dataset_dir, \"validation\")\n",
        "\n",
        "        # Verify structure\n",
        "        if verify_dataset_structure(train_dir, validation_dir):\n",
        "            print(\"Dataset setup completed successfully!\")\n",
        "            return train_dir, validation_dir\n",
        "        else:\n",
        "            raise Exception(\"Dataset structure verification failed\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Download failed: {str(e)}\")\n",
        "        print(\"Creating minimal demo dataset...\")\n",
        "        return create_minimal_demo_dataset()\n",
        "\n",
        "def verify_dataset_structure(train_dir, validation_dir):\n",
        "    \"\"\"\n",
        "    Verify that the dataset has the expected structure and content.\n",
        "\n",
        "    Args:\n",
        "        train_dir: Training directory path\n",
        "        validation_dir: Validation directory path\n",
        "\n",
        "    Returns:\n",
        "        bool: True if structure is valid\n",
        "    \"\"\"\n",
        "    required_dirs = [\n",
        "        os.path.join(train_dir, 'cats'),\n",
        "        os.path.join(train_dir, 'dogs'),\n",
        "        os.path.join(validation_dir, 'cats'),\n",
        "        os.path.join(validation_dir, 'dogs')\n",
        "    ]\n",
        "\n",
        "    print(\"\\nVerifying dataset structure...\")\n",
        "    for dir_path in required_dirs:\n",
        "        if not os.path.exists(dir_path):\n",
        "            print(f\"Missing directory: {dir_path}\")\n",
        "            return False\n",
        "\n",
        "        # Count image files\n",
        "        image_files = [f for f in os.listdir(dir_path)\n",
        "                      if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "        print(f\"{len(image_files)} images in {os.path.basename(dir_path)}\")\n",
        "\n",
        "        if len(image_files) == 0:\n",
        "            print(f\"No images found in: {dir_path}\")\n",
        "            return False\n",
        "\n",
        "    return True\n",
        "\n",
        "def create_minimal_demo_dataset():\n",
        "    \"\"\"\n",
        "    Create a minimal dataset with synthetic images for demonstration.\n",
        "    This runs if the download fails for any reason.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (train_dir, validation_dir)\n",
        "    \"\"\"\n",
        "    print(\"Creating minimal demo dataset with synthetic images...\")\n",
        "\n",
        "    try:\n",
        "        from PIL import Image\n",
        "        import numpy as np\n",
        "\n",
        "        # Create directory structure in current directory\n",
        "        dataset_dir = os.path.join(os.getcwd(), \"demo_cats_dogs\")\n",
        "        train_dir = os.path.join(dataset_dir, \"train\")\n",
        "        validation_dir = os.path.join(dataset_dir, \"validation\")\n",
        "\n",
        "        for split in ['train', 'validation']:\n",
        "            for category in ['cats', 'dogs']:\n",
        "                os.makedirs(os.path.join(dataset_dir, split, category), exist_ok=True)\n",
        "\n",
        "        # Create synthetic images with distinctive patterns\n",
        "        def create_synthetic_image(category, size=(150, 150)):\n",
        "            \"\"\"Create a synthetic image with distinctive patterns for each class.\"\"\"\n",
        "            image = np.random.randint(50, 200, (size[0], size[1], 3), dtype=np.uint8)\n",
        "\n",
        "            if category == 'cats':\n",
        "                # Add horizontal stripes for cats\n",
        "                for i in range(0, size[0], 20):\n",
        "                    image[i:i+5, :, :] = [255, 200, 100]  # Orange stripes\n",
        "            else:  # dogs\n",
        "                # Add diagonal pattern for dogs\n",
        "                for i in range(size[0]):\n",
        "                    for j in range(size[1]):\n",
        "                        if (i + j) % 30 < 10:\n",
        "                            image[i, j, :] = [100, 150, 255]  # Blue diagonal\n",
        "\n",
        "            return Image.fromarray(image)\n",
        "\n",
        "        # Generate training images\n",
        "        print(\"Generating training images...\")\n",
        "        for category in ['cats', 'dogs']:\n",
        "            category_dir = os.path.join(train_dir, category)\n",
        "            for i in range(50):  # 50 images per category\n",
        "                img = create_synthetic_image(category)\n",
        "                img.save(os.path.join(category_dir, f'{category}_{i:03d}.jpg'))\n",
        "\n",
        "        # Generate validation images\n",
        "        print(\"Generating validation images...\")\n",
        "        for category in ['cats', 'dogs']:\n",
        "            category_dir = os.path.join(validation_dir, category)\n",
        "            for i in range(10):  # 10 images per category\n",
        "                img = create_synthetic_image(category)\n",
        "                img.save(os.path.join(category_dir, f'{category}_val_{i:03d}.jpg'))\n",
        "\n",
        "        print(f\"Demo dataset created at: {dataset_dir}\")\n",
        "        print(\"NOTE: This is synthetic data for demonstration only!\")\n",
        "\n",
        "        return train_dir, validation_dir\n",
        "\n",
        "    except ImportError:\n",
        "        print(\"PIL (Pillow) not available. Install with: pip install pillow\")\n",
        "        raise\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to create demo dataset: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "def create_data_generators(train_dir, validation_dir, img_height=150, img_width=150, batch_size=32):\n",
        "    \"\"\"\n",
        "    Create data generators for training and validation with data augmentation.\n",
        "\n",
        "    Data augmentation helps prevent overfitting by creating variations of training images.\n",
        "    This is crucial for small datasets and improves model generalization.\n",
        "\n",
        "    Args:\n",
        "        train_dir: Path to training data directory\n",
        "        validation_dir: Path to validation data directory\n",
        "        img_height: Target height for resized images\n",
        "        img_width: Target width for resized images\n",
        "        batch_size: Number of images per batch\n",
        "\n",
        "    Returns:\n",
        "        tuple: (train_generator, validation_generator)\n",
        "    \"\"\"\n",
        "    print(f\"\\nCreating data generators...\")\n",
        "    print(f\"Training directory: {train_dir}\")\n",
        "    print(f\"Validation directory: {validation_dir}\")\n",
        "    print(f\"Image size: {img_height}x{img_width}\")\n",
        "    print(f\"Batch size: {batch_size}\")\n",
        "\n",
        "    # TODO: STUDENT FILL IN\n",
        "    # Create ImageDataGenerator for training data with augmentation\n",
        "    # Include: rescale=1./255 (normalize), rotation_range=20, width_shift_range=0.2,\n",
        "    # height_shift_range=0.2, shear_range=0.2, zoom_range=0.2, horizontal_flip=True\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=________,           # Normalize pixel values to [0,1]\n",
        "        rotation_range=________,    # Randomly rotate images up to 20 degrees\n",
        "        width_shift_range=________,  # Randomly shift images horizontally by 20%\n",
        "        height_shift_range=________, # Randomly shift images vertically by 20%\n",
        "        shear_range=________,       # Randomly apply shear transformations\n",
        "        zoom_range=________,        # Randomly zoom in/out by 20%\n",
        "        horizontal_flip=________,   # Randomly flip images horizontally\n",
        "        fill_mode='nearest'         # Fill in newly created pixels\n",
        "    )\n",
        "\n",
        "    # TODO: STUDENT FILL IN\n",
        "    # Create ImageDataGenerator for validation data (only rescaling, no augmentation)\n",
        "    # We don't augment validation data because we want consistent evaluation\n",
        "    validation_datagen = ImageDataGenerator(rescale=________)\n",
        "\n",
        "    # TODO: STUDENT FILL IN\n",
        "    # Create training data generator\n",
        "    # Use flow_from_directory with target_size=(img_height, img_width),\n",
        "    # batch_size=batch_size, class_mode='binary' (for cats vs dogs)\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(________, ________),\n",
        "        batch_size=________,\n",
        "        class_mode='________'  # 'binary' for 2 classes (cats vs dogs)\n",
        "    )\n",
        "\n",
        "    # TODO: STUDENT FILL IN\n",
        "    # Create validation data generator (similar to training but with validation_datagen and validation_dir)\n",
        "    validation_generator = validation_datagen.flow_from_directory(\n",
        "        ________,  # validation_dir\n",
        "        target_size=(________, ________),\n",
        "        batch_size=________,\n",
        "        class_mode='________'\n",
        "    )\n",
        "\n",
        "    print(f\"Classes found: {train_generator.class_indices}\")\n",
        "    print(f\"Training samples: {train_generator.samples}\")\n",
        "    print(f\"Validation samples: {validation_generator.samples}\")\n",
        "\n",
        "    return train_generator, validation_generator\n",
        "\n",
        "def visualize_sample_images(train_generator):\n",
        "    \"\"\"\n",
        "    Display a batch of training images to understand the data.\n",
        "    This helps verify that data loading and augmentation are working correctly.\n",
        "\n",
        "    Args:\n",
        "        train_generator: Training data generator\n",
        "    \"\"\"\n",
        "    print(\"Displaying sample images...\")\n",
        "\n",
        "    # Get a batch of images and labels\n",
        "    sample_batch = next(train_generator)\n",
        "    images, labels = sample_batch\n",
        "\n",
        "    # Plot first 8 images\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    for i in range(min(8, len(images))):\n",
        "        plt.subplot(2, 4, i + 1)\n",
        "        plt.imshow(images[i])\n",
        "        # Convert label to class name (0=cats, 1=dogs by default)\n",
        "        label_name = 'Dog' if labels[i] == 1 else 'Cat'\n",
        "        plt.title(f'Label: {label_name}')\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.suptitle('Sample Training Images (with augmentation)')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# PART 2: CONVOLUTIONAL NEURAL NETWORK ARCHITECTURE\n",
        "# ============================================================================\n",
        "\n",
        "def create_simple_cnn(img_height=150, img_width=150):\n",
        "    \"\"\"\n",
        "    Create a simple CNN model for binary classification.\n",
        "\n",
        "    CNN Architecture Explanation:\n",
        "    1. Convolutional layers extract features (edges, shapes, textures)\n",
        "       - Early layers detect simple features (edges, corners)\n",
        "       - Deeper layers detect complex features (shapes, objects)\n",
        "    2. Pooling layers reduce spatial dimensions and computation\n",
        "       - MaxPooling keeps the strongest activation in each region\n",
        "    3. Dense layers perform final classification based on extracted features\n",
        "\n",
        "    Args:\n",
        "        img_height: Input image height\n",
        "        img_width: Input image width\n",
        "\n",
        "    Returns:\n",
        "        keras.Model: Compiled CNN model\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"CREATING SIMPLE CNN MODEL\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    model = keras.Sequential(name=\"Simple_CNN\")\n",
        "\n",
        "    # TODO: STUDENT FILL IN\n",
        "    # First Convolutional Block\n",
        "    # Add Conv2D layer: 32 filters, (3,3) kernel, 'relu' activation\n",
        "    # Specify input_shape=(img_height, img_width, 3) for RGB images\n",
        "    model.add(layers.Conv2D(\n",
        "        filters=________,\n",
        "        kernel_size=(________, ________),\n",
        "        activation='________',\n",
        "        input_shape=(________, ________, ________),  # (height, width, channels)\n",
        "        name='conv2d_1'\n",
        "    ))\n",
        "\n",
        "    # TODO: STUDENT FILL IN\n",
        "    # Add MaxPooling2D layer with (2,2) pool size to reduce spatial dimensions\n",
        "    model.add(layers.MaxPooling2D(pool_size=(________, ________), name='maxpool_1'))\n",
        "\n",
        "    # TODO: STUDENT FILL IN\n",
        "    # Second Convolutional Block\n",
        "    # Add Conv2D layer: 64 filters, (3,3) kernel, 'relu' activation\n",
        "    # More filters allow learning more complex features\n",
        "    model.add(layers.Conv2D(\n",
        "        filters=________,\n",
        "        kernel_size=(________, ________),\n",
        "        activation='________',\n",
        "        name='conv2d_2'\n",
        "    ))\n",
        "    model.add(layers.MaxPooling2D(pool_size=(________, ________), name='maxpool_2'))\n",
        "\n",
        "    # TODO: STUDENT FILL IN\n",
        "    # Third Convolutional Block\n",
        "    # Add Conv2D layer: 128 filters, (3,3) kernel, 'relu' activation\n",
        "    # Even more filters for abstract/high-level features\n",
        "    model.add(layers.Conv2D(\n",
        "        filters=________,\n",
        "        kernel_size=(________, ________),\n",
        "        activation='________',\n",
        "        name='conv2d_3'\n",
        "    ))\n",
        "    model.add(layers.MaxPooling2D(pool_size=(________, ________), name='maxpool_3'))\n",
        "\n",
        "    # TODO: STUDENT FILL IN\n",
        "    # Flatten the 3D feature maps to 1D for dense layers\n",
        "    # This converts from spatial features to a vector\n",
        "    model.add(layers.Flatten(name='flatten'))\n",
        "\n",
        "    # TODO: STUDENT FILL IN\n",
        "    # Add Dense layer with 512 units and 'relu' activation\n",
        "    # This learns combinations of the extracted features\n",
        "    model.add(layers.Dense(units=________, activation='________', name='dense_1'))\n",
        "\n",
        "    # TODO: STUDENT FILL IN\n",
        "    # Add Dropout layer with 0.5 rate to prevent overfitting\n",
        "    # Randomly sets 50% of neurons to 0 during training\n",
        "    model.add(layers.Dropout(rate=________, name='dropout'))\n",
        "\n",
        "    # TODO: STUDENT FILL IN\n",
        "    # Output layer: 1 unit with 'sigmoid' activation for binary classification\n",
        "    # Sigmoid outputs probability between 0 and 1\n",
        "    model.add(layers.Dense(units=________, activation='________', name='output'))\n",
        "\n",
        "    # TODO: STUDENT FILL IN\n",
        "    # Compile model: optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']\n",
        "    # Adam: adaptive learning rate optimizer\n",
        "    # Binary crossentropy: loss function for binary classification\n",
        "    model.compile(\n",
        "        optimizer='________',\n",
        "        loss='________',\n",
        "        metrics=['________']\n",
        "    )\n",
        "\n",
        "    print(\"\\nSimple CNN Architecture:\")\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n",
        "def create_improved_cnn(img_height=150, img_width=150):\n",
        "    \"\"\"\n",
        "    Create an improved CNN model with batch normalization and more layers.\n",
        "\n",
        "    Improvements over simple CNN:\n",
        "    - Batch normalization for better training stability\n",
        "    - More convolutional layers for better feature extraction\n",
        "    - Additional regularization techniques\n",
        "    - Deeper architecture for more complex pattern recognition\n",
        "\n",
        "    Args:\n",
        "        img_height: Input image height\n",
        "        img_width: Input image width\n",
        "\n",
        "    Returns:\n",
        "        keras.Model: Compiled improved CNN model\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"CREATING IMPROVED CNN MODEL\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    model = keras.Sequential(name=\"Improved_CNN\")\n",
        "\n",
        "    # First Block: Basic feature detection\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
        "                           input_shape=(img_height, img_width, 3), name='conv2d_1'))\n",
        "    model.add(layers.BatchNormalization(name='bn_1'))  # Normalize activations\n",
        "    model.add(layers.MaxPooling2D((2, 2), name='maxpool_1'))\n",
        "\n",
        "    # Second Block: More complex features\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu', name='conv2d_2'))\n",
        "    model.add(layers.BatchNormalization(name='bn_2'))\n",
        "    model.add(layers.MaxPooling2D((2, 2), name='maxpool_2'))\n",
        "\n",
        "    # Third Block: High-level features\n",
        "    model.add(layers.Conv2D(128, (3, 3), activation='relu', name='conv2d_3'))\n",
        "    model.add(layers.BatchNormalization(name='bn_3'))\n",
        "    model.add(layers.MaxPooling2D((2, 2), name='maxpool_3'))\n",
        "\n",
        "    # Fourth Block: Abstract features\n",
        "    model.add(layers.Conv2D(256, (3, 3), activation='relu', name='conv2d_4'))\n",
        "    model.add(layers.BatchNormalization(name='bn_4'))\n",
        "    model.add(layers.MaxPooling2D((2, 2), name='maxpool_4'))\n",
        "\n",
        "    # Dense layers for classification\n",
        "    model.add(layers.Flatten(name='flatten'))\n",
        "    model.add(layers.Dense(512, activation='relu', name='dense_1'))\n",
        "    model.add(layers.Dropout(0.5, name='dropout_1'))\n",
        "    model.add(layers.Dense(256, activation='relu', name='dense_2'))\n",
        "    model.add(layers.Dropout(0.3, name='dropout_2'))\n",
        "    model.add(layers.Dense(1, activation='sigmoid', name='output'))\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    print(\"\\nImproved CNN Architecture:\")\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "id": "68APjeeVNGjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# PART 3: TRAINING AND EVALUATION\n",
        "# ============================================================================\n",
        "\n",
        "def train_model(model, train_generator, validation_generator, epochs=10):\n",
        "    \"\"\"\n",
        "    Train the CNN model with early stopping and learning rate reduction.\n",
        "\n",
        "    Callbacks help improve training:\n",
        "    - EarlyStopping: Prevents overfitting by stopping when validation loss stops improving\n",
        "    - ReduceLROnPlateau: Reduces learning rate when training plateaus\n",
        "\n",
        "    Args:\n",
        "        model: Keras model to train\n",
        "        train_generator: Training data generator\n",
        "        validation_generator: Validation data generator\n",
        "        epochs: Maximum number of epochs\n",
        "\n",
        "    Returns:\n",
        "        keras.callbacks.History: Training history\n",
        "    \"\"\"\n",
        "    print(f\"\\nTraining {model.name}...\")\n",
        "    print(f\"Max epochs: {epochs}\")\n",
        "\n",
        "    # TODO: STUDENT FILL IN\n",
        "    # Define callbacks for better training\n",
        "    # EarlyStopping: monitor='val_loss', patience=3, restore_best_weights=True\n",
        "    # ReduceLROnPlateau: monitor='val_loss', factor=0.2, patience=2\n",
        "    callbacks = [\n",
        "        keras.callbacks.EarlyStopping(\n",
        "            monitor='________',        # Monitor validation loss\n",
        "            patience=________,         # Wait 3 epochs before stopping\n",
        "            restore_best_weights=________  # Restore best weights found\n",
        "        ),\n",
        "        keras.callbacks.ReduceLROnPlateau(\n",
        "            monitor='________',        # Monitor validation loss\n",
        "            factor=________,           # Reduce learning rate by factor of 5 (0.2)\n",
        "            patience=________          # Wait 2 epochs before reducing\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    # Calculate steps per epoch\n",
        "    # This determines how many batches to process per epoch\n",
        "    steps_per_epoch = max(1, train_generator.samples // train_generator.batch_size)\n",
        "    validation_steps = max(1, validation_generator.samples // validation_generator.batch_size)\n",
        "\n",
        "    print(f\"Steps per epoch: {steps_per_epoch}\")\n",
        "    print(f\"Validation steps: {validation_steps}\")\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=steps_per_epoch,\n",
        "        epochs=epochs,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=validation_steps,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1  # Show progress bar\n",
        "    )\n",
        "\n",
        "    return history\n",
        "\n",
        "def evaluate_model(model, validation_generator):\n",
        "    \"\"\"\n",
        "    Evaluate model performance and create predictions.\n",
        "\n",
        "    Args:\n",
        "        model: Trained Keras model\n",
        "        validation_generator: Validation data generator\n",
        "\n",
        "    Returns:\n",
        "        tuple: (test_accuracy, predictions, true_labels)\n",
        "    \"\"\"\n",
        "    print(f\"\\n\" + \"=\"*50)\n",
        "    print(f\"EVALUATING {model.name.upper()}\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Reset generator to start from beginning\n",
        "    validation_generator.reset()\n",
        "\n",
        "    # Get test accuracy\n",
        "    test_loss, test_accuracy = model.evaluate(validation_generator, verbose=0)\n",
        "    print(f\"Test Loss: {test_loss:.4f}\")\n",
        "    print(f\"Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
        "\n",
        "    # Get predictions for detailed analysis\n",
        "    validation_generator.reset()\n",
        "    predictions = model.predict(validation_generator, verbose=0)\n",
        "\n",
        "    # Get true labels\n",
        "    true_labels = validation_generator.classes\n",
        "\n",
        "    # Convert predictions to binary (0 or 1)\n",
        "    pred_labels = (predictions > 0.5).astype(int).flatten()\n",
        "\n",
        "    # Classification report\n",
        "    class_names = ['Cat', 'Dog']\n",
        "    print(f\"\\nClassification Report for {model.name}:\")\n",
        "    print(classification_report(true_labels, pred_labels, target_names=class_names))\n",
        "\n",
        "    return test_accuracy, pred_labels, true_labels\n",
        "\n",
        "def plot_training_history(history, model_name):\n",
        "    \"\"\"\n",
        "    Plot training history to visualize learning progress.\n",
        "\n",
        "    This helps identify:\n",
        "    - Overfitting (training accuracy >> validation accuracy)\n",
        "    - Underfitting (both accuracies are low)\n",
        "    - Good fit (training and validation curves are close)\n",
        "\n",
        "    Args:\n",
        "        history: Training history object\n",
        "        model_name: Name of the model for title\n",
        "    \"\"\"\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    # Training and validation accuracy\n",
        "    ax1.plot(history.history['accuracy'], label='Training Accuracy', marker='o')\n",
        "    ax1.plot(history.history['val_accuracy'], label='Validation Accuracy', marker='s')\n",
        "    ax1.set_title(f'{model_name} - Training vs Validation Accuracy')\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Accuracy')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True)\n",
        "\n",
        "    # Training and validation loss\n",
        "    ax2.plot(history.history['loss'], label='Training Loss', marker='o')\n",
        "    ax2.plot(history.history['val_loss'], label='Validation Loss', marker='s')\n",
        "    ax2.set_title(f'{model_name} - Training vs Validation Loss')\n",
        "    ax2.set_xlabel('Epoch')\n",
        "    ax2.set_ylabel('Loss')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, model_name):\n",
        "    \"\"\"\n",
        "    Plot confusion matrix for binary classification.\n",
        "\n",
        "    Confusion matrix shows:\n",
        "    - True Positives (TP): Correctly predicted dogs\n",
        "    - True Negatives (TN): Correctly predicted cats\n",
        "    - False Positives (FP): Incorrectly predicted dogs (actually cats)\n",
        "    - False Negatives (FN): Incorrectly predicted cats (actually dogs)\n",
        "\n",
        "    Args:\n",
        "        y_true: True labels\n",
        "        y_pred: Predicted labels\n",
        "        model_name: Name of the model for title\n",
        "    \"\"\"\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Cat', 'Dog'], yticklabels=['Cat', 'Dog'])\n",
        "    plt.title(f'{model_name} - Confusion Matrix')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.show()\n",
        "\n",
        "def visualize_predictions(model, validation_generator, num_images=8):\n",
        "    \"\"\"\n",
        "    Visualize model predictions on sample images.\n",
        "    This helps understand what the model has learned and where it makes mistakes.\n",
        "\n",
        "    Args:\n",
        "        model: Trained model\n",
        "        validation_generator: Validation data generator\n",
        "        num_images: Number of images to display\n",
        "    \"\"\"\n",
        "    # Get a batch of images\n",
        "    validation_generator.reset()\n",
        "    batch = next(validation_generator)\n",
        "    images, true_labels = batch\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = model.predict(images[:num_images])\n",
        "\n",
        "    # Plot images with predictions\n",
        "    plt.figure(figsize=(15, 8))\n",
        "    for i in range(num_images):\n",
        "        plt.subplot(2, 4, i + 1)\n",
        "        plt.imshow(images[i])\n",
        "\n",
        "        # Get predicted and true labels\n",
        "        pred_prob = predictions[i][0]\n",
        "        pred_label = 'Dog' if pred_prob > 0.5 else 'Cat'\n",
        "        true_label = 'Dog' if true_labels[i] == 1 else 'Cat'\n",
        "\n",
        "        # Color: green if correct, red if incorrect\n",
        "        color = 'green' if pred_label == true_label else 'red'\n",
        "\n",
        "        plt.title(f'True: {true_label}\\nPred: {pred_label} ({pred_prob:.2f})',\n",
        "                 color=color, fontsize=10)\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.suptitle(f'{model.name} - Sample Predictions', fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "UHloXj7mNOJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# PART 4: MAIN EXECUTION\n",
        "# ============================================================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to run the complete CNN experiment.\n",
        "    \"\"\"\n",
        "    print(\"CATS VS DOGS CLASSIFICATION WITH CNN\")\n",
        "    print(\"Working in current directory to avoid permission issues\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Download and prepare dataset\n",
        "    train_dir, validation_dir = download_cats_dogs_dataset()\n",
        "\n",
        "    # Create data generators\n",
        "    train_generator, validation_generator = create_data_generators(\n",
        "        train_dir, validation_dir,\n",
        "        img_height=150, img_width=150,\n",
        "        batch_size=32\n",
        "    )\n",
        "\n",
        "    # Visualize sample images\n",
        "    print(\"\\nVisualizing sample training images...\")\n",
        "    visualize_sample_images(train_generator)\n",
        "\n",
        "    # Create and train simple CNN\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"TRAINING SIMPLE CNN\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    simple_cnn = create_simple_cnn(150, 150)\n",
        "    history_simple = train_model(simple_cnn, train_generator, validation_generator, epochs=8)\n",
        "\n",
        "    # Evaluate simple CNN\n",
        "    acc_simple, pred_simple, true_simple = evaluate_model(simple_cnn, validation_generator)\n",
        "\n",
        "    # Visualize training history\n",
        "    plot_training_history(history_simple, \"Simple CNN\")\n",
        "    plot_confusion_matrix(true_simple, pred_simple, \"Simple CNN\")\n",
        "    visualize_predictions(simple_cnn, validation_generator)\n",
        "\n",
        "    # Create and train improved CNN\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"TRAINING IMPROVED CNN\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    improved_cnn = create_improved_cnn(150, 150)\n",
        "    history_improved = train_model(improved_cnn, train_generator, validation_generator, epochs=8)\n",
        "\n",
        "    # Evaluate improved CNN\n",
        "    acc_improved, pred_improved, true_improved = evaluate_model(improved_cnn, validation_generator)\n",
        "\n",
        "    # Visualize training history\n",
        "    plot_training_history(history_improved, \"Improved CNN\")\n",
        "    plot_confusion_matrix(true_improved, pred_improved, \"Improved CNN\")\n",
        "    visualize_predictions(improved_cnn, validation_generator)\n",
        "\n",
        "    # Final comparison\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"FINAL COMPARISON\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Simple CNN Accuracy:   {acc_simple:.4f} ({acc_simple*100:.2f}%)\")\n",
        "    print(f\"Improved CNN Accuracy: {acc_improved:.4f} ({acc_improved*100:.2f}%)\")\n",
        "\n",
        "    if acc_improved > acc_simple:\n",
        "        improvement = ((acc_improved - acc_simple) / acc_simple) * 100\n",
        "        print(f\"Improvement: {improvement:.2f}%\")\n",
        "\n",
        "    # Model parameters comparison\n",
        "    print(f\"\\nModel Complexity Comparison:\")\n",
        "    print(f\"Simple CNN Parameters:   {simple_cnn.count_params():,}\")\n",
        "    print(f\"Improved CNN Parameters: {improved_cnn.count_params():,}\")\n",
        "\n",
        "    # Save models\n",
        "    simple_cnn.save(\"simple_cnn_model.h5\")\n",
        "    improved_cnn.save(\"improved_cnn_model.h5\")\n",
        "    print(\"\\nModels saved to current directory!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ],
      "metadata": {
        "id": "ueeNkuplNTPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DISCUSSION QUESTIONS FOR STUDENTS\n",
        "\n",
        "1. Why are CNNs better suited for image classification compared to regular dense networks?\n",
        "   Hint: Think about spatial relationships and parameter sharing\n",
        "\n",
        "2. What is the purpose of each layer type:\n",
        "   - Convolutional layers: Feature extraction with learnable filters\n",
        "   - Pooling layers: Dimensionality reduction and translation invariance\n",
        "   - Dropout layers: Regularization to prevent overfitting\n",
        "   - Batch normalization: Stabilize training and improve convergence\n",
        "\n",
        "3. How does data augmentation help improve model performance?\n",
        "   Hint: Think about dataset size and model generalization\n",
        "\n",
        "4. What happens to the spatial dimensions as data flows through the CNN?\n",
        "   Hint: Track the output shape after each layer\n",
        "\n",
        "5. Why do we use different numbers of filters in different layers?\n",
        "   Hint: Think about feature hierarchy (simple â†’ complex)\n",
        "\n",
        "6. How do early stopping and learning rate reduction help during training?\n",
        "   Hint: Think about overfitting and optimization\n",
        "\n",
        "7. Experiment: Try different architectures. What happens if you:\n",
        "   - Remove pooling layers?\n",
        "   - Use different filter sizes (5x5 instead of 3x3)?\n",
        "   - Add more/fewer layers?\n",
        "   - Change the number of filters?\n",
        "\n",
        "8. What are the trade-offs between model complexity and performance?\n",
        "   Hint: Consider training time, memory usage, and accuracy\n",
        "\n",
        "TROUBLESHOOTING:\n",
        "- If download fails, the code will create synthetic demo images\n",
        "- All files are saved to current directory (no permission issues)\n",
        "- Required packages: pip install tensorflow pillow scikit-learn matplotlib seaborn\n",
        "\n",
        "EXPECTED RESULTS:\n",
        "- Simple CNN: ~75-85% accuracy\n",
        "- Improved CNN: ~85-95% accuracy  \n",
        "- Training should complete in 5-15 minutes depending on hardware\n"
      ],
      "metadata": {
        "id": "vARjxFSYNWgh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "doYfOwMbNV68"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
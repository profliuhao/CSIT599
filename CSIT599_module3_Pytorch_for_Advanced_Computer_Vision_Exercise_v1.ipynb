{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPJDvcekE9LX7WTPXz9rpG6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/profliuhao/CSIT599/blob/main/CSIT599_module3_Pytorch_for_Advanced_Computer_Vision_Exercise_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN Architecture Evolution: From LeNet to ResNet - PyTorch Version\n",
        "### Exercise for Students - SEQUENTIAL LEARNING APPROACH\n",
        "\n",
        "This exercise demonstrates the evolution of CNN architectures using PyTorch:\n",
        "1. Traditional CNN (Basic vanilla CNN)\n",
        "2. LeNet-5 (1998) - The pioneer\n",
        "3. AlexNet (2012) - Deep learning breakthrough\n",
        "4. VGG-16 (2014) - Deep and uniform\n",
        "5. Inception/GoogLeNet (2014) - Multi-scale features\n",
        "6. ResNet (2015) - Skip connections revolution\n",
        "\n",
        "BONUS: Using pre-built models from torchvision and Hugging Face\n",
        "\n",
        "Dataset: CIFAR-10 (32x32 color images, 10 classes)\n",
        "\n",
        "Instructions:\n",
        "1. Fill in the blanks marked with \"# TODO: STUDENT FILL IN\"\n",
        "2. Run each architecture sequentially\n",
        "3. Compare custom vs pre-built implementations\n",
        "4. Explore Hugging Face vision models\n",
        "\n",
        "Requirements:\n",
        "pip install torch torchvision transformers pillow matplotlib"
      ],
      "metadata": {
        "id": "rGniZ7qv4we9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(42)\n",
        "\n",
        "# Check device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "0_jB97jj40Pn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================================================\n",
        "# STEP 1: DATA PREPARATION - CIFAR-10\n",
        "# ============================================================================\n",
        "\n",
        "def load_cifar10(batch_size=128):\n",
        "    \"\"\"\n",
        "    Load and preprocess CIFAR-10 dataset.\n",
        "\n",
        "    PyTorch uses transforms for data preprocessing and augmentation.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (train_loader, test_loader, classes)\n",
        "    \"\"\"\n",
        "    print(\"STEP 1: LOADING CIFAR-10 DATASET\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Define transforms\n",
        "    # TODO: STUDENT FILL IN\n",
        "    # transforms.ToTensor() converts images to tensors and normalizes to [0,1]\n",
        "    # transforms.Normalize with mean=[0.5, 0.5, 0.5] and std=[0.5, 0.5, 0.5]\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((________, ________, ________),   # mean for RGB\n",
        "                           (________, ________, ________))     # std for RGB\n",
        "    ])\n",
        "\n",
        "    # Load training data\n",
        "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                            download=True, transform=transform)\n",
        "    trainloader = DataLoader(trainset, batch_size=batch_size,\n",
        "                            shuffle=True, num_workers=2)\n",
        "\n",
        "    # Load test data\n",
        "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                           download=True, transform=transform)\n",
        "    testloader = DataLoader(testset, batch_size=batch_size,\n",
        "                           shuffle=False, num_workers=2)\n",
        "\n",
        "    classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "    print(f\"Training samples: {len(trainset)}\")\n",
        "    print(f\"Test samples: {len(testset)}\")\n",
        "    print(f\"Classes: {classes}\")\n",
        "    print(f\"Batch size: {batch_size}\")\n",
        "\n",
        "    return trainloader, testloader, classes\n",
        "\n",
        "def visualize_cifar10_samples(trainloader, classes):\n",
        "    \"\"\"Visualize sample images from CIFAR-10.\"\"\"\n",
        "    # Get a batch of images\n",
        "    dataiter = iter(trainloader)\n",
        "    images, labels = next(dataiter)\n",
        "\n",
        "    # Convert images for display\n",
        "    images = images / 2 + 0.5  # Unnormalize\n",
        "\n",
        "    # Plot\n",
        "    fig, axes = plt.subplots(4, 8, figsize=(12, 6))\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        if i < len(images):\n",
        "            # Convert from (C, H, W) to (H, W, C)\n",
        "            img = images[i].permute(1, 2, 0).numpy()\n",
        "            ax.imshow(img)\n",
        "            ax.set_title(classes[labels[i]], fontsize=8)\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.suptitle('CIFAR-10 Sample Images')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "hSWQo-3844bu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STEP 2: TRADITIONAL CNN (BASELINE)\n",
        "# ============================================================================\n",
        "\n",
        "class TraditionalCNN(nn.Module):\n",
        "    \"\"\"\n",
        "    Traditional/Vanilla CNN as baseline.\n",
        "\n",
        "    PyTorch uses nn.Module as base class for all neural networks.\n",
        "    Define layers in __init__ and forward pass in forward().\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(TraditionalCNN, self).__init__()\n",
        "\n",
        "        # TODO: STUDENT FILL IN\n",
        "        # Define convolutional layers\n",
        "        # nn.Conv2d(in_channels, out_channels, kernel_size)\n",
        "        # First conv: 3 input channels (RGB), 32 output channels, 3x3 kernel\n",
        "        self.conv1 = nn.Conv2d(________, ________, ________, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # TODO: STUDENT FILL IN\n",
        "        # Second conv: 32 input channels, 64 output channels, 3x3 kernel\n",
        "        self.conv2 = nn.Conv2d(________, ________, ________, padding=1)\n",
        "\n",
        "        # TODO: STUDENT FILL IN\n",
        "        # Third conv: 64 input channels, 128 output channels, 3x3 kernel\n",
        "        self.conv3 = nn.Conv2d(________, ________, ________, padding=1)\n",
        "\n",
        "        # TODO: STUDENT FILL IN\n",
        "        # Fully connected layers\n",
        "        # nn.Linear(input_features, output_features)\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, ________)  # 128 units\n",
        "        self.fc2 = nn.Linear(________, ________)     # 128 to 10 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass defines the computation performed at every call.\n",
        "\n",
        "        Args:\n",
        "            x: Input tensor of shape (batch_size, 3, 32, 32)\n",
        "\n",
        "        Returns:\n",
        "            Output tensor of shape (batch_size, 10)\n",
        "        \"\"\"\n",
        "        # TODO: STUDENT FILL IN\n",
        "        # Apply conv1, ReLU, pooling\n",
        "        # F.relu() is the ReLU activation function\n",
        "        x = self.pool(F.relu(self.conv1(________)))\n",
        "\n",
        "        # TODO: STUDENT FILL IN\n",
        "        # Apply conv2, ReLU, pooling\n",
        "        x = self.pool(F.relu(self.conv2(________)))\n",
        "\n",
        "        # TODO: STUDENT FILL IN\n",
        "        # Apply conv3, ReLU, pooling\n",
        "        x = self.pool(F.relu(self.conv3(________)))\n",
        "\n",
        "        # TODO: STUDENT FILL IN\n",
        "        # Flatten: view(-1, ...) reshapes the tensor\n",
        "        x = x.view(-1, ________ * ________ * ________)  # 128 * 4 * 4\n",
        "\n",
        "        # TODO: STUDENT FILL IN\n",
        "        # Apply fc1 with ReLU\n",
        "        x = F.relu(self.fc1(________))\n",
        "\n",
        "        # TODO: STUDENT FILL IN\n",
        "        # Apply fc2 (no activation - done in loss function)\n",
        "        x = self.fc2(________)\n",
        "\n",
        "        return x\n",
        "\n",
        "def create_traditional_cnn():\n",
        "    \"\"\"Create and initialize Traditional CNN.\"\"\"\n",
        "    print(\"\\nSTEP 2: BUILDING TRADITIONAL CNN (BASELINE)\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    model = TraditionalCNN().to(device)\n",
        "\n",
        "    # Print model architecture\n",
        "    print(\"\\nTraditional CNN Architecture:\")\n",
        "    print(model)\n",
        "\n",
        "    # Count parameters\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    print(f\"\\nTotal parameters: {total_params:,}\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "mEGcZ0zo47Nw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================================================\n",
        "# STEP 3: LeNet-5 (1998) - THE PIONEER\n",
        "# ============================================================================\n",
        "\n",
        "class LeNet5(nn.Module):\n",
        "    \"\"\"\n",
        "    LeNet-5 architecture (adapted for CIFAR-10).\n",
        "\n",
        "    Original LeNet-5 (1998) by Yann LeCun.\n",
        "    First successful CNN architecture.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(LeNet5, self).__init__()\n",
        "\n",
        "        # Convolutional layers (using original tanh activation)\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5, padding=2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(16 * 6 * 6, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Use tanh (original activation) instead of ReLU\n",
        "        x = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
        "        x = F.max_pool2d(torch.tanh(self.conv2(x)), 2)\n",
        "        x = x.view(-1, 16 * 6 * 6)\n",
        "        x = torch.tanh(self.fc1(x))\n",
        "        x = torch.tanh(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "def create_lenet5():\n",
        "    \"\"\"Create LeNet-5 model.\"\"\"\n",
        "    print(\"\\nSTEP 3: BUILDING LeNet-5 (1998)\")\n",
        "    print(\"=\"*50)\n",
        "    print(\"Innovation: First successful CNN architecture!\")\n",
        "\n",
        "    model = LeNet5().to(device)\n",
        "    print(\"\\nLeNet-5 Architecture:\")\n",
        "    print(model)\n",
        "\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    print(f\"\\nTotal parameters: {total_params:,}\")\n",
        "    print(\"Note: Using tanh activation (original) instead of ReLU\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "9OAjgLMx497_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STEP 4: AlexNet (2012) - DEEP LEARNING BREAKTHROUGH\n",
        "# ============================================================================\n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "    \"\"\"\n",
        "    AlexNet architecture (adapted for CIFAR-10).\n",
        "\n",
        "    Original AlexNet (2012) - Deep learning revolution.\n",
        "    Key innovations: ReLU + Dropout.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(AlexNet, self).__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 96, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(96, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(256, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.5),  # KEY: Dropout introduced!\n",
        "            nn.Linear(256 * 4 * 4, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "def create_alexnet():\n",
        "    \"\"\"Create AlexNet model.\"\"\"\n",
        "    print(\"\\nSTEP 4: BUILDING AlexNet (2012)\")\n",
        "    print(\"=\"*50)\n",
        "    print(\"Innovation: ReLU activation + Dropout + Deep network!\")\n",
        "\n",
        "    model = AlexNet().to(device)\n",
        "    print(\"\\nAlexNet Architecture:\")\n",
        "    print(model)\n",
        "\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    print(f\"\\nTotal parameters: {total_params:,}\")\n",
        "    print(\"Key innovations: ReLU + Dropout!\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "tTJ-NhFp5Bkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STEP 5: VGG-16 (2014) - DEEP AND UNIFORM\n",
        "# ============================================================================\n",
        "\n",
        "class VGG16(nn.Module):\n",
        "    \"\"\"\n",
        "    VGG-16 architecture (simplified for CIFAR-10).\n",
        "\n",
        "    Key innovation: Very deep network with uniform 3x3 filters.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(VGG16, self).__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            # Block 1\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Block 2\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Block 3\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(256 * 4 * 4, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "def create_vgg16():\n",
        "    \"\"\"Create VGG-16 model.\"\"\"\n",
        "    print(\"\\nSTEP 5: BUILDING VGG-16 (2014)\")\n",
        "    print(\"=\"*50)\n",
        "    print(\"Innovation: Very deep network + Uniform 3x3 filters!\")\n",
        "\n",
        "    model = VGG16().to(device)\n",
        "    print(\"\\nVGG-16 Architecture:\")\n",
        "    print(model)\n",
        "\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    print(f\"\\nTotal parameters: {total_params:,}\")\n",
        "    print(\"Key innovation: Very deep with uniform 3x3 convolutions!\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "mZq0YTbs5CR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STEP 6: Inception Module and GoogLeNet\n",
        "# ============================================================================\n",
        "\n",
        "class InceptionModule(nn.Module):\n",
        "    \"\"\"\n",
        "    Inception module for multi-scale feature extraction.\n",
        "\n",
        "    Key innovation: Parallel convolutions at different scales.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, ch1x1, ch3x3red, ch3x3, ch5x5red, ch5x5, pool_proj):\n",
        "        super(InceptionModule, self).__init__()\n",
        "\n",
        "        # 1x1 convolution branch\n",
        "        self.branch1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, ch1x1, kernel_size=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # 3x3 convolution branch\n",
        "        self.branch2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, ch3x3red, kernel_size=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(ch3x3red, ch3x3, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # 5x5 convolution branch\n",
        "        self.branch3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, ch5x5red, kernel_size=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(ch5x5red, ch5x5, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # Max pooling branch\n",
        "        self.branch4 = nn.Sequential(\n",
        "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
        "            nn.Conv2d(in_channels, pool_proj, kernel_size=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO: STUDENT FILL IN\n",
        "        # Apply all branches and concatenate along channel dimension\n",
        "        branch1 = self.branch1(________)\n",
        "        branch2 = self.branch2(________)\n",
        "        branch3 = self.branch3(________)\n",
        "        branch4 = self.branch4(________)\n",
        "\n",
        "        # Concatenate along channel dimension (dim=1)\n",
        "        outputs = torch.cat([________, ________, ________, ________], dim=________)\n",
        "        return outputs\n",
        "\n",
        "class InceptionNet(nn.Module):\n",
        "    \"\"\"Inception/GoogLeNet architecture (simplified for CIFAR-10).\"\"\"\n",
        "    def __init__(self):\n",
        "        super(InceptionNet, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        # Inception modules\n",
        "        self.inception3a = InceptionModule(64, 64, 96, 128, 16, 32, 32)\n",
        "        self.inception3b = InceptionModule(256, 128, 128, 192, 32, 96, 64)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.inception4a = InceptionModule(480, 192, 96, 208, 16, 48, 64)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "        self.fc = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.inception3a(x)\n",
        "        x = self.inception3b(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.inception4a(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "def create_inception():\n",
        "    \"\"\"Create Inception model.\"\"\"\n",
        "    print(\"\\nSTEP 6: BUILDING Inception/GoogLeNet (2014)\")\n",
        "    print(\"=\"*50)\n",
        "    print(\"Innovation: Multi-scale feature extraction with Inception modules!\")\n",
        "\n",
        "    model = InceptionNet().to(device)\n",
        "    print(\"\\nInception Architecture:\")\n",
        "    print(model)\n",
        "\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    print(f\"\\nTotal parameters: {total_params:,}\")\n",
        "    print(\"Key innovation: Parallel multi-scale convolutions!\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "FB0-f14C5HAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STEP 7: ResNet - SKIP CONNECTIONS REVOLUTION\n",
        "# ============================================================================\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Residual block with skip connection.\n",
        "\n",
        "    Key innovation: x + F(x) instead of just F(x).\n",
        "    Enables training very deep networks.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "\n",
        "        # TODO: STUDENT FILL IN\n",
        "        # Main path: two conv layers\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        # Shortcut connection\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1,\n",
        "                         stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO: STUDENT FILL IN\n",
        "        # Main path\n",
        "        out = F.relu(self.bn1(self.conv1(________)))\n",
        "        out = self.bn2(self.conv2(________))\n",
        "\n",
        "        # TODO: STUDENT FILL IN\n",
        "        # Add skip connection: out + shortcut\n",
        "        out += self.shortcut(________)\n",
        "        out = F.relu(________)\n",
        "\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    \"\"\"ResNet architecture (simplified for CIFAR-10).\"\"\"\n",
        "    def __init__(self):\n",
        "        super(ResNet, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # Residual blocks\n",
        "        self.layer1 = self._make_layer(64, 64, 2, stride=1)\n",
        "        self.layer2 = self._make_layer(64, 128, 2, stride=2)\n",
        "        self.layer3 = self._make_layer(128, 256, 2, stride=2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(256, 10)\n",
        "\n",
        "    def _make_layer(self, in_channels, out_channels, num_blocks, stride):\n",
        "        layers = []\n",
        "        layers.append(ResidualBlock(in_channels, out_channels, stride))\n",
        "        for _ in range(1, num_blocks):\n",
        "            layers.append(ResidualBlock(out_channels, out_channels, 1))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "def create_resnet():\n",
        "    \"\"\"Create ResNet model.\"\"\"\n",
        "    print(\"\\nSTEP 7: BUILDING ResNet (2015)\")\n",
        "    print(\"=\"*50)\n",
        "    print(\"Innovation: Skip connections enable very deep networks!\")\n",
        "\n",
        "    model = ResNet().to(device)\n",
        "    print(\"\\nResNet Architecture:\")\n",
        "    print(model)\n",
        "\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    print(f\"\\nTotal parameters: {total_params:,}\")\n",
        "    print(\"Key innovation: Skip connections (x + F(x))!\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "r3gNRnVA5PU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# BONUS: USING PRE-BUILT MODELS FROM TORCHVISION\n",
        "# ============================================================================\n",
        "\n",
        "def use_pretrained_resnet():\n",
        "    \"\"\"\n",
        "    Load pre-trained ResNet from torchvision.\n",
        "\n",
        "    torchvision provides pre-trained models on ImageNet.\n",
        "    We need to modify the final layer for CIFAR-10 (10 classes).\n",
        "    \"\"\"\n",
        "    print(\"\\nBONUS: USING PRE-TRAINED ResNet from torchvision\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Load pre-trained ResNet18\n",
        "    model = torchvision.models.resnet18(pretrained=True)\n",
        "\n",
        "    # Modify final layer for CIFAR-10 (10 classes instead of 1000)\n",
        "    num_features = model.fc.in_features\n",
        "    model.fc = nn.Linear(num_features, 10)\n",
        "\n",
        "    model = model.to(device)\n",
        "\n",
        "    print(\"Pre-trained ResNet18 loaded and modified for CIFAR-10\")\n",
        "    print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "def use_pretrained_vgg():\n",
        "    \"\"\"Load pre-trained VGG from torchvision.\"\"\"\n",
        "    print(\"\\nBONUS: USING PRE-TRAINED VGG from torchvision\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    model = torchvision.models.vgg16(pretrained=True)\n",
        "\n",
        "    # Modify classifier for CIFAR-10\n",
        "    model.classifier[6] = nn.Linear(4096, 10)\n",
        "\n",
        "    model = model.to(device)\n",
        "\n",
        "    print(\"Pre-trained VGG16 loaded and modified for CIFAR-10\")\n",
        "    print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "SCkO_Yu75ouG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# BONUS: USING HUGGING FACE TRANSFORMERS FOR VISION\n",
        "# ============================================================================\n",
        "\n",
        "def use_huggingface_vit():\n",
        "    \"\"\"\n",
        "    Use Vision Transformer (ViT) from Hugging Face.\n",
        "\n",
        "    Note: ViT is not a CNN - it's a transformer-based architecture.\n",
        "    This shows the modern direction of computer vision.\n",
        "\n",
        "    Requires: pip install transformers\n",
        "    \"\"\"\n",
        "    print(\"\\nBONUS: USING Vision Transformer from Hugging Face\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    try:\n",
        "        from transformers import ViTForImageClassification, ViTConfig\n",
        "\n",
        "        # Create ViT configuration for CIFAR-10\n",
        "        config = ViTConfig(\n",
        "            image_size=32,\n",
        "            patch_size=4,\n",
        "            num_channels=3,\n",
        "            num_labels=10,\n",
        "            hidden_size=384,\n",
        "            num_hidden_layers=6,\n",
        "            num_attention_heads=6\n",
        "        )\n",
        "\n",
        "        # Create model\n",
        "        model = ViTForImageClassification(config)\n",
        "        model = model.to(device)\n",
        "\n",
        "        print(\"Vision Transformer (ViT) loaded from Hugging Face\")\n",
        "        print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "        print(\"\\nNote: ViT uses transformers (attention), not convolutions!\")\n",
        "        print(\"This represents the modern evolution beyond CNNs.\")\n",
        "\n",
        "        return model\n",
        "    except ImportError:\n",
        "        print(\"Hugging Face transformers not installed.\")\n",
        "        print(\"Install with: pip install transformers\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "PMz-EJrm5pXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# TRAINING AND EVALUATION FUNCTIONS\n",
        "# ============================================================================\n",
        "\n",
        "def train_model(model, trainloader, testloader, epochs=10, lr=0.001):\n",
        "    \"\"\"\n",
        "    Train a PyTorch model.\n",
        "\n",
        "    Args:\n",
        "        model: PyTorch model\n",
        "        trainloader: Training data loader\n",
        "        testloader: Test data loader\n",
        "        epochs: Number of epochs\n",
        "        lr: Learning rate\n",
        "\n",
        "    Returns:\n",
        "        tuple: (training_history, training_time)\n",
        "    \"\"\"\n",
        "    print(f\"\\nTraining {model.__class__.__name__}...\")\n",
        "\n",
        "    # Define loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    # Training history\n",
        "    history = {'train_loss': [], 'train_acc': [], 'test_loss': [], 'test_acc': []}\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for i, (inputs, labels) in enumerate(trainloader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward + backward + optimize\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Statistics\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        train_loss = running_loss / len(trainloader)\n",
        "        train_acc = correct / total\n",
        "\n",
        "        # Evaluation phase\n",
        "        model.eval()\n",
        "        test_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in testloader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                test_loss += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += labels.size(0)\n",
        "                correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        test_loss = test_loss / len(testloader)\n",
        "        test_acc = correct / total\n",
        "\n",
        "        # Store history\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['test_loss'].append(test_loss)\n",
        "        history['test_acc'].append(test_acc)\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{epochs}] '\n",
        "              f'Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | '\n",
        "              f'Test Loss: {test_loss:.4f} Acc: {test_acc:.4f}')\n",
        "\n",
        "    training_time = time.time() - start_time\n",
        "    print(f\"Training completed in {training_time:.2f} seconds\")\n",
        "\n",
        "    return history, training_time\n",
        "\n",
        "def evaluate_model(model, testloader):\n",
        "    \"\"\"Evaluate model on test set.\"\"\"\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in testloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print(f\"Test Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "R7Mo-0Ry5rVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# COMPARISON AND VISUALIZATION\n",
        "# ============================================================================\n",
        "\n",
        "def compare_models(results):\n",
        "    \"\"\"Compare all trained models.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"MODEL COMPARISON\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    print(f\"\\n{'Model':<20} {'Accuracy':<12} {'Time (s)':<12} {'Params':<12}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    for name, data in results.items():\n",
        "        print(f\"{name:<20} {data['accuracy']:<12.4f} \"\n",
        "              f\"{data['time']:<12.2f} {data['params']:<12,}\")\n",
        "\n",
        "    # Rankings\n",
        "    sorted_by_acc = sorted(results.items(), key=lambda x: x[1]['accuracy'], reverse=True)\n",
        "    print(\"\\nðŸ† Accuracy Rankings:\")\n",
        "    for i, (name, data) in enumerate(sorted_by_acc, 1):\n",
        "        print(f\"  {i}. {name}: {data['accuracy']:.4f}\")\n",
        "\n",
        "def plot_comparison(results):\n",
        "    \"\"\"Plot comparison charts.\"\"\"\n",
        "    models = list(results.keys())\n",
        "    accuracies = [results[m]['accuracy'] for m in models]\n",
        "    params = [results[m]['params'] / 1e6 for m in models]\n",
        "    times = [results[m]['time'] for m in models]\n",
        "\n",
        "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "    # Accuracy\n",
        "    colors = ['red', 'orange', 'yellow', 'lightgreen', 'cyan', 'blue']\n",
        "    ax1.bar(models, accuracies, color=colors)\n",
        "    ax1.set_title('Test Accuracy Comparison')\n",
        "    ax1.set_ylabel('Accuracy')\n",
        "    ax1.set_ylim([0, 1])\n",
        "    ax1.tick_params(axis='x', rotation=45)\n",
        "\n",
        "    # Parameters\n",
        "    ax2.bar(models, params, color=colors)\n",
        "    ax2.set_title('Model Complexity (Parameters)')\n",
        "    ax2.set_ylabel('Parameters (Millions)')\n",
        "    ax2.tick_params(axis='x', rotation=45)\n",
        "\n",
        "    # Training time\n",
        "    ax3.bar(models, times, color=colors)\n",
        "    ax3.set_title('Training Time (10 epochs)')\n",
        "    ax3.set_ylabel('Time (seconds)')\n",
        "    ax3.tick_params(axis='x', rotation=45)\n",
        "\n",
        "    # Accuracy vs Parameters\n",
        "    ax4.scatter(params, accuracies, c=range(len(models)), cmap='viridis', s=200)\n",
        "    for i, model in enumerate(models):\n",
        "        ax4.annotate(model, (params[i], accuracies[i]), fontsize=8)\n",
        "    ax4.set_xlabel('Parameters (Millions)')\n",
        "    ax4.set_ylabel('Accuracy')\n",
        "    ax4.set_title('Accuracy vs Model Complexity')\n",
        "    ax4.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('pytorch_cnn_comparison.png', dpi=150)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "yv0B_9i15uqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDGmtn4D4QRY"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# MAIN EXECUTION\n",
        "# ============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"CNN ARCHITECTURE EVOLUTION - PyTorch Version\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # STEP 1: Load and prepare data\n",
        "    print(\"\\nðŸ“¥ Downloading and preparing CIFAR-10 dataset...\")\n",
        "    print(\"(This may take a few minutes on first run)\")\n",
        "    trainloader, testloader, classes = load_cifar10(batch_size=128)\n",
        "    visualize_cifar10_samples(trainloader, classes)\n",
        "\n",
        "    # Dictionary to store results\n",
        "    results = {}\n",
        "\n",
        "    # Define architectures\n",
        "    architectures = [\n",
        "        (\"Traditional CNN\", create_traditional_cnn),\n",
        "        (\"LeNet-5\", create_lenet5),\n",
        "        (\"AlexNet\", create_alexnet),\n",
        "        (\"VGG-16\", create_vgg16),\n",
        "        (\"Inception\", create_inception),\n",
        "        (\"ResNet\", create_resnet)\n",
        "    ]\n",
        "\n",
        "    EPOCHS = 10\n",
        "\n",
        "    # Train each architecture\n",
        "    for name, create_func in architectures:\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"TRAINING: {name}\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        model = create_func()\n",
        "        history, training_time = train_model(model, trainloader, testloader,\n",
        "                                            epochs=EPOCHS)\n",
        "        accuracy = evaluate_model(model, testloader)\n",
        "\n",
        "        results[name] = {\n",
        "            'accuracy': accuracy,\n",
        "            'time': training_time,\n",
        "            'params': sum(p.numel() for p in model.parameters()),\n",
        "            'history': history\n",
        "        }\n",
        "\n",
        "        print(f\"âœ… {name} completed!\")\n",
        "\n",
        "    # Compare all models\n",
        "    compare_models(results)\n",
        "    plot_comparison(results)\n",
        "\n",
        "    print(\"\\nðŸŽ‰ EXERCISE COMPLETED!\")\n",
        "\n",
        "    # Bonus: Show how to use pre-built models\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"BONUS: PRE-BUILT MODELS\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"\\nTo use pre-built models from torchvision:\")\n",
        "    print(\"  model = torchvision.models.resnet18(pretrained=True)\")\n",
        "    print(\"  # Modify final layer for your task\")\n",
        "    print(\"\\nTo use Hugging Face transformers:\")\n",
        "    print(\"  from transformers import ViTForImageClassification\")\n",
        "    print(\"  model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## ðŸŽ“ PYTORCH-SPECIFIC LEARNING POINTS:\n",
        "\n",
        "1. PyTorch Model Structure:\n",
        "   - Define layers in __init__()\n",
        "   - Implement forward pass in forward()\n",
        "   - Use nn.Module as base class\n",
        "\n",
        "2. Training Loop:\n",
        "   - model.train() for training mode\n",
        "   - model.eval() for evaluation mode\n",
        "   - optimizer.zero_grad() before backward()\n",
        "   - loss.backward() for backpropagation\n",
        "   - optimizer.step() to update weights\n",
        "\n",
        "3. Data Loading:\n",
        "   - Use torch.utils.data.DataLoader\n",
        "   - transforms for preprocessing\n",
        "   - Automatic batching and shuffling\n",
        "\n",
        "4. GPU Acceleration:\n",
        "   - .to(device) to move model/data to GPU\n",
        "   - Automatic GPU usage if available\n",
        "\n",
        "5. Pre-built Models:\n",
        "   - torchvision.models for CNNs\n",
        "   - transformers library for modern architectures\n",
        "   - Transfer learning capabilities\n",
        "\n",
        "ðŸ”§ REQUIREMENTS:\n",
        "pip install torch torchvision transformers pillow matplotlib scikit-learn\n",
        "\n",
        "ðŸš€ NEXT STEPS:\n",
        "1. Try transfer learning with pre-trained models\n",
        "2. Experiment with data augmentation\n",
        "3. Implement custom loss functions\n",
        "4. Explore model ensembling\n",
        "5. Try Vision Transformers (ViT)\n"
      ],
      "metadata": {
        "id": "NsrPEwKu51X8"
      }
    }
  ]
}
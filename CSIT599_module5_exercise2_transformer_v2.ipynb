{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/profliuhao/CSIT599/blob/main/CSIT599_module5_exercise2_transformer_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 2: Transformer Model for Neural Machine Translation\n",
        "\n",
        "English to German Translation\n",
        "\n",
        "Student Name: ____________________\n",
        "\n",
        "\n",
        "Learning Objectives:\n",
        "1. Understand positional encoding\n",
        "2. Implement multi-head self-attention\n",
        "3. Build complete Transformer architecture\n",
        "4. Track both loss and accuracy metrics\n",
        "5. Compare with Seq2Seq models\n",
        "\n",
        "Instructions:\n",
        "- Fill in the blanks marked with \\_\\_\\_BLANK___\n",
        "- Each blank is a simple parameter, function name, or dimension\n",
        "- Run the code to train the Transformer\n",
        "- Compare results with Exercise 1\n",
        "\n"
      ],
      "metadata": {
        "id": "T5xqu7jIy2jY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import os\n",
        "import re\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"GPU Available: {len(tf.config.list_physical_devices('GPU')) > 0}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3JbbJ1-aEln",
        "outputId": "4ff8deed-2420-4799-ed17-d5e88ecf04c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.19.0\n",
            "GPU Available: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# HYPERPARAMETERS\n",
        "# ==============================================================================\n",
        "\n",
        "# Define hyperparameters for the Transformer model and training process.\n",
        "# These values can be tuned to optimize performance.\n",
        "BATCH_SIZE = 128\n",
        "D_MODEL = 256          # Model dimension (embedding size) - This is the size of the vector representation for each token.\n",
        "NUM_HEADS = 8          # Number of attention heads - Multi-head attention allows the model to jointly attend to information from different representation subspaces.\n",
        "NUM_LAYERS = 2         # Number of encoder/decoder layers - Determines the depth of the Transformer network.\n",
        "D_FF = 256             # Feed-forward network dimension - The inner dimension of the position-wise feed-forward network.\n",
        "DROPOUT_RATE = 0.1     # Dropout rate for regularization, applied to embeddings, attention, and FFN outputs.\n",
        "MAX_LENGTH = 20        # Maximum sequence length for input and target sentences. Longer sentences will be truncated, shorter ones padded.\n",
        "EPOCHS = 10             # Number of training epochs.\n"
      ],
      "metadata": {
        "id": "AbVMGTc3aHiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# DATA LOADING (Same as Exercise 1)\n",
        "# ==============================================================================\n",
        "\n",
        "def download_data():\n",
        "    \"\"\"Download the English-German translation dataset from a URL if it doesn't already exist.\"\"\"\n",
        "    url = \"http://www.manythings.org/anki/deu-eng.zip\"\n",
        "    filename = \"deu-eng.zip\"\n",
        "\n",
        "    if not os.path.exists(\"deu.txt\"):\n",
        "        print(\"Downloading dataset...\")\n",
        "        # Add User-Agent header to avoid 406 Not Acceptable error from some servers.\n",
        "        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
        "        req = urllib.request.Request(url, headers=headers)\n",
        "        with urllib.request.urlopen(req) as response, open(filename, 'wb') as out_file:\n",
        "            out_file.write(response.read())\n",
        "\n",
        "        # Extract the dataset from the downloaded zip file.\n",
        "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "            zip_ref.extractall()\n",
        "        os.remove(filename) # Remove the zip file after extraction.\n",
        "        print(\"Download complete!\")\n",
        "    else:\n",
        "        print(\"Dataset already exists.\")\n",
        "\n",
        "def preprocess_sentence(sentence):\n",
        "    \"\"\"Preprocesses a single sentence by lowercasing, adding spaces around punctuation, cleaning extra spaces, and adding start/end tokens.\"\"\"\n",
        "    sentence = sentence.lower().strip() # Convert to lowercase and remove leading/trailing whitespace.\n",
        "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence) # Add spaces around punctuation for tokenization.\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # Replace multiple spaces with a single space.\n",
        "    sentence = sentence.strip() # Remove any new leading/trailing spaces.\n",
        "    sentence = '<start> ' + sentence + ' <end>' # Add special start and end tokens.\n",
        "    return sentence\n",
        "\n",
        "def load_dataset(num_examples=10000):\n",
        "    \"\"\"Loads and preprocesses the English-German dataset, filtering by MAX_LENGTH.\"\"\"\n",
        "    download_data()\n",
        "\n",
        "    with open('deu.txt', 'r', encoding='utf-8') as f:\n",
        "        lines = f.read().strip().split('\\n')\n",
        "\n",
        "    pairs = []\n",
        "    for line in lines[:num_examples]: # Iterate through a limited number of examples.\n",
        "        parts = line.split('\\t') # Sentences are tab-separated.\n",
        "        if len(parts) >= 2:\n",
        "            eng = preprocess_sentence(parts[0])\n",
        "            deu = preprocess_sentence(parts[1])\n",
        "            # Only include pairs where both English and German sentences are within MAX_LENGTH.\n",
        "            if len(eng.split()) <= MAX_LENGTH and len(deu.split()) <= MAX_LENGTH:\n",
        "                pairs.append([eng, deu])\n",
        "\n",
        "    print(f\"Loaded {len(pairs)} sentence pairs\")\n",
        "    return zip(*pairs) # Unzip the pairs into separate English and German lists.\n",
        "\n",
        "# Load and tokenize data for a specified number of examples.\n",
        "input_texts, target_texts = load_dataset(num_examples=15000)\n",
        "input_texts = list(input_texts) # Convert zip object to list.\n",
        "target_texts = list(target_texts) # Convert zip object to list.\n",
        "\n",
        "# Initialize tokenizers for English (input) and German (target) languages.\n",
        "# oov_token='<UNK>' handles out-of-vocabulary words.\n",
        "input_tokenizer = keras.preprocessing.text.Tokenizer(\n",
        "    filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n',\n",
        "    oov_token='<UNK>'\n",
        ")\n",
        "target_tokenizer = keras.preprocessing.text.Tokenizer(\n",
        "    filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n',\n",
        "    oov_token='<UNK>'\n",
        ")\n",
        "\n",
        "\n",
        "# Fit tokenizers on the respective texts to build word indices.\n",
        "input_tokenizer.fit_on_texts(input_texts)\n",
        "target_tokenizer.fit_on_texts(target_texts)\n",
        "\n",
        "# Convert text sequences to integer sequences using the fitted tokenizers.\n",
        "input_sequences = input_tokenizer.texts_to_sequences(input_texts)\n",
        "target_sequences = target_tokenizer.texts_to_sequences(target_texts)\n",
        "\n",
        "# Pad sequences to MAX_LENGTH. 'post' padding adds zeros at the end.\n",
        "input_sequences = keras.preprocessing.sequence.pad_sequences(\n",
        "    input_sequences, maxlen=MAX_LENGTH, padding='post')\n",
        "target_sequences = keras.preprocessing.sequence.pad_sequences(\n",
        "    target_sequences, maxlen=MAX_LENGTH, padding='post')\n",
        "\n",
        "# Calculate vocabulary sizes. Add 1 for the reserved 0 (padding) token.\n",
        "input_vocab_size = len(input_tokenizer.word_index) + 1\n",
        "target_vocab_size = len(target_tokenizer.word_index) + 1\n",
        "\n",
        "print(f\"\\nVocabulary sizes:\")\n",
        "print(f\"English: {input_vocab_size}\")\n",
        "print(f\"German: {target_vocab_size}\")\n",
        "\n",
        "# Split data into training and validation sets (80/20 split).\n",
        "split_idx = int(0.8 * len(input_sequences))\n",
        "train_input = input_sequences[:split_idx]\n",
        "train_target = target_sequences[:split_idx]\n",
        "val_input = input_sequences[split_idx:]\n",
        "val_target = target_sequences[split_idx:]\n",
        "\n",
        "print(f\"\\nTraining samples: {len(train_input)}\")\n",
        "print(f\"Validation samples: {len(val_input)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hH5D2jlPaJeC",
        "outputId": "ed947967-d878-4ab0-aa97-e5908fdefd7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset already exists.\n",
            "Loaded 15000 sentence pairs\n",
            "\n",
            "Vocabulary sizes:\n",
            "English: 2909\n",
            "German: 4715\n",
            "\n",
            "Training samples: 12000\n",
            "Validation samples: 3000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PART 1: POSITIONAL ENCODING"
      ],
      "metadata": {
        "id": "kF9tg1JKaMtE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# PART 1: POSITIONAL ENCODING\n",
        "# ==============================================================================\n",
        "\n",
        "def get_positional_encoding(seq_len, d_model):\n",
        "    \"\"\"\n",
        "    Create positional encoding matrix using sine and cosine functions.\n",
        "    This helps the Transformer understand the position of words in a sequence,\n",
        "    as it has no inherent recurrence or convolution.\n",
        "\n",
        "    Formula:\n",
        "    PE(pos, 2i)   = sin(pos / 10000^(2i/d_model))\n",
        "    PE(pos, 2i+1) = cos(pos / 10000^(2i/d_model))\n",
        "\n",
        "    Args:\n",
        "        seq_len: Maximum sequence length.\n",
        "        d_model: Model dimension (embedding size).\n",
        "\n",
        "    Returns:\n",
        "        pos_encoding: A Tensor of shape [1, seq_len, d_model] containing the positional encodings.\n",
        "    \"\"\"\n",
        "    # Create position indices: [0, 1, 2, ..., seq_len-1].\n",
        "    # np.newaxis adds a new dimension, making its shape [seq_len, 1]\n",
        "    # This allows for broadcasting when multiplied with div_term.\n",
        "    position = np.arange(seq_len)[:, np.newaxis]  # shape: [seq_len, 1]\n",
        "\n",
        "    # Create dimension indices for the divisor term: [0, 2, 4, ..., d_model-2].\n",
        "    # These correspond to the '2i' in the formula.\n",
        "    div_term = np.arange(0, ___BLANK___, ___BLANK___)  # ___BLANK___ step size (we want even indices for 2i)\n",
        "\n",
        "    # Calculate the scaling factor: 1 / 10000^(2i/d_model).\n",
        "    # This is equivalent to exp(-2i * log(10000) / d_model).\n",
        "    div_term = 1 / np.___BLANK___(10000, ___BLANK___ / d_model) # ___BLANK___\n",
        "\n",
        "    # Initialize the positional encoding matrix with zeros.\n",
        "    pos_encoding = np.zeros((seq_len, d_model))\n",
        "\n",
        "    # Apply sine function to even indices (0, 2, 4, ...).\n",
        "    # pos_encoding[:, 0::2] selects all rows and even-indexed columns.\n",
        "    pos_encoding[:, 0::2] = np.___BLANK___(position * div_term)  # ___BLANK___\n",
        "\n",
        "    # Apply cosine function to odd indices (1, 3, 5, ...).\n",
        "    # pos_encoding[:, 1::2] selects all rows and odd-indexed columns.\n",
        "    pos_encoding[:, 1::2] = np.___BLANK___(position * div_term)  # ___BLANK___\n",
        "\n",
        "    # Add a batch dimension at the beginning, resulting in shape [1, seq_len, d_model].\n",
        "    # This allows it to be broadcasted across batch samples when added to embeddings.\n",
        "    pos_encoding = pos_encoding[np.newaxis, ...]  # Shape: [1, seq_len, d_model]\n",
        "\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)"
      ],
      "metadata": {
        "id": "Uah8qB2VaTEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PART 2: SCALED DOT-PRODUCT ATTENTION"
      ],
      "metadata": {
        "id": "UCoLC4gbaYxe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# PART 2: SCALED DOT-PRODUCT ATTENTION\n",
        "# ==============================================================================\n",
        "\n",
        "def scaled_dot_product_attention(query, key, value, mask=None):\n",
        "    \"\"\"\n",
        "    Calculates attention weights and applies them to values.\n",
        "    This is the core mechanism of the Transformer, determining how much focus\n",
        "    each part of the input sequence should receive when processing another part.\n",
        "\n",
        "    Formula:\n",
        "    Attention(Q, K, V) = softmax(QK^T / sqrt(d_k)) V\n",
        "\n",
        "    Args:\n",
        "        query: Tensor of shape [batch_size, num_heads, seq_len_q, depth]. Represents what we are looking for.\n",
        "        key:   Tensor of shape [batch_size, num_heads, seq_len_k, depth]. Represents what is available.\n",
        "        value: Tensor of shape [batch_size, num_heads, seq_len_v, depth]. The information to extract, corresponding to keys.\n",
        "        mask:  Tensor, optional. Used to hide future tokens (look-ahead mask) or padding tokens.\n",
        "               Shape: [batch_size, 1, 1, seq_len_k] (for padding mask) or [batch_size, 1, seq_len_q, seq_len_k] (for look-ahead mask).\n",
        "\n",
        "    Returns:\n",
        "        output: Tensor of shape [batch_size, num_heads, seq_len_q, depth]. The weighted sum of values.\n",
        "        attention_weights: Tensor of shape [batch_size, num_heads, seq_len_q, seq_len_k]. The attention scores.\n",
        "    \"\"\"\n",
        "    # Calculate the dot product of Query and Key, transposing the last two dimensions of Key.\n",
        "    # This operation `Q @ K^T` computes the similarity between query and key vectors.\n",
        "    # The resulting shape is [batch, heads, seq_len_q, seq_len_k].\n",
        "    matmul_qk = tf.matmul(___BLANK___, ___BLANK___, transpose_b=___BLANK___)  # ___BLANK___ (True because we need K^T)\n",
        "\n",
        "    # Scale the dot products by the square root of the depth (dimension of key vectors).\n",
        "    # This scaling prevents the dot products from becoming too large, which can lead to\n",
        "    # extremely small gradients during softmax, hindering effective learning.\n",
        "    depth = tf.cast(tf.shape(key)[-1], tf.float32) # Get the last dimension of key (d_k)\n",
        "\n",
        "    # Apply square root for scaling. `tf.math.sqrt` is the TensorFlow function for this.\n",
        "    scaled_attention_logits = matmul_qk / tf.math.sqrt(depth)\n",
        "\n",
        "    # Add the mask (if provided) to the scaled attention logits.\n",
        "    # Masked positions (typically padding or future tokens) are set to a very large negative number.\n",
        "    # When softmax is applied, these positions will become approximately zero, effectively ignoring them.\n",
        "    if mask is not None:\n",
        "        scaled_attention_logits += (mask * -1e9)  # (Common choice for a large negative number)\n",
        "\n",
        "    # Apply softmax to get attention weights.\n",
        "    # Softmax is applied along the last axis (seq_len_k), ensuring that the weights\n",
        "    # for each query position sum to 1 across all key positions.\n",
        "    attention_weights = tf.nn.___BLANK___(scaled_attention_logits, axis=___BLANK___)  # ___BLANK___ (Apply softmax across the key sequence length dimension, -1)\n",
        "\n",
        "    # Multiply the attention weights by the Value tensor.\n",
        "    # This operation performs a weighted sum of the value vectors, where the weights\n",
        "    # are the attention scores, giving more importance to relevant information.\n",
        "    output = tf.matmul(attention_weights, value)\n",
        "\n",
        "    return output, attention_weights"
      ],
      "metadata": {
        "id": "B1YsvNuHab60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PART 3: MULTI-HEAD ATTENTION"
      ],
      "metadata": {
        "id": "AdFSdj2Hae77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# PART 3: MULTI-HEAD ATTENTION\n",
        "# ==============================================================================\n",
        "\n",
        "class MultiHeadAttention(layers.Layer):\n",
        "    \"\"\"\n",
        "    Multi-Head Attention layer.\n",
        "\n",
        "    This layer improves the model's ability to focus on different positions.\n",
        "    It splits the model dimension (d_model) into multiple heads, performs\n",
        "    scaled dot-product attention in parallel for each head, then concatenates\n",
        "    and projects the results back to the original d_model dimension.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "\n",
        "        # Assert that d_model is divisible by num_heads.\n",
        "        # This is crucial because we need to split the d_model into `num_heads`\n",
        "        # equal parts, each of `depth` size.\n",
        "        assert d_model % num_heads == 0  # (Ensures even division)\n",
        "\n",
        "        # Calculate the `depth` of each attention head.\n",
        "        # d_model = num_heads * depth\n",
        "        self.depth = d_model // num_heads\n",
        "\n",
        "        # Linear projections for Query, Key, and Value.\n",
        "        # These dense layers transform the input into Q, K, V matrices.\n",
        "        self.wq = layers.Dense(d_model)\n",
        "        self.wk = layers.Dense(d_model)\n",
        "        self.wv = layers.Dense(d_model)\n",
        "\n",
        "        # Final linear projection after concatenating all attention heads.\n",
        "        self.dense = layers.Dense(d_model)\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        \"\"\"\n",
        "        Splits the last dimension (d_model) of the input tensor `x`\n",
        "        into `num_heads` and `depth` dimensions.\n",
        "\n",
        "        Args:\n",
        "            x: Input tensor of shape [batch_size, seq_len, d_model].\n",
        "            batch_size: The batch size of the input.\n",
        "\n",
        "        Returns:\n",
        "            Tensor of shape [batch_size, num_heads, seq_len, depth].\n",
        "        \"\"\"\n",
        "        # Reshape the input from [batch_size, seq_len, d_model]\n",
        "        # to [batch_size, seq_len, num_heads, depth].\n",
        "        # The `-1` automatically infers the `seq_len` dimension.\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))  # (Reshaping to separate heads)\n",
        "\n",
        "        # Transpose the tensor to change the order of dimensions.\n",
        "        # We want [batch_size, num_heads, seq_len, depth] for parallel computation across heads.\n",
        "        # The original order was [batch, seq_len, num_heads, depth],\n",
        "        # so we permute to swap `seq_len` (index 1) and `num_heads` (index 2).\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])  # (Permuting dimensions)\n",
        "\n",
        "    def call(self, query, key, value, mask=None):\n",
        "        \"\"\"\n",
        "        Performs the multi-head attention operation.\n",
        "\n",
        "        Args:\n",
        "            query, key, value: Input tensors, typically of shape [batch_size, seq_len, d_model].\n",
        "            mask: Optional attention mask.\n",
        "\n",
        "        Returns:\n",
        "            output: Tensor of shape [batch_size, seq_len, d_model]. The result of multi-head attention.\n",
        "            attention_weights: Tensor of shape [batch_size, num_heads, seq_len_q, seq_len_k]. The attention scores.\n",
        "        \"\"\"\n",
        "        batch_size = tf.shape(query)[0]\n",
        "\n",
        "        # Apply linear projections to Q, K, V.\n",
        "        # This transforms them to `d_model` dimensions before splitting.\n",
        "        query = self.wq(query)  # [batch_size, seq_len, d_model]\n",
        "        key = self.wk(key)\n",
        "        value = self.wv(value)\n",
        "\n",
        "        # Split the projected Q, K, V into multiple heads.\n",
        "        # Each now has shape [batch_size, num_heads, seq_len, depth].\n",
        "        query = self.split_heads(query, batch_size)\n",
        "        key = self.split_heads(key, batch_size)\n",
        "        value = self.split_heads(value, batch_size)\n",
        "\n",
        "        # Perform scaled dot-product attention for all heads in parallel.\n",
        "        # This results in `scaled_attention` (attended values) and `attention_weights` (scores).\n",
        "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "            query, key, value, mask\n",
        "        )\n",
        "\n",
        "        # Concatenate the output from all attention heads.\n",
        "        # First, transpose back to [batch_size, seq_len, num_heads, depth]\n",
        "        # to prepare for reshaping to d_model.\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (Reversing the transpose operation)\n",
        "\n",
        "        # Reshape the tensor back to its original `d_model` dimension.\n",
        "        # This combines the `num_heads` and `depth` dimensions back into `d_model`.\n",
        "        # Resulting shape: [batch_size, seq_len, d_model].\n",
        "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))  # (Reshaping to combine heads)\n",
        "\n",
        "        # Apply a final linear projection to the concatenated output.\n",
        "        # This is a learned transformation that helps integrate the information from all heads.\n",
        "        output = self.dense(concat_attention)\n",
        "\n",
        "        return output, attention_weights"
      ],
      "metadata": {
        "id": "pxl230yNahMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PART 4: FEED-FORWARD NETWORK"
      ],
      "metadata": {
        "id": "PYZ1oiHFakjX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# PART 4: FEED-FORWARD NETWORK\n",
        "# ==============================================================================\n",
        "\n",
        "class FeedForwardNetwork(layers.Layer):\n",
        "    \"\"\"\n",
        "    Position-wise Feed-Forward Network.\n",
        "\n",
        "    This network is applied independently to each position in the sequence.\n",
        "    It consists of two linear transformations with a ReLU activation in between,\n",
        "    often expressed as: FFN(x) = max(0, xW1 + b1)W2 + b2.\n",
        "    It allows the model to process each position's representation further.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, d_ff, dropout_rate=0.1):\n",
        "        super(FeedForwardNetwork, self).__init__()\n",
        "\n",
        "        # The first dense layer expands the dimension from d_model to d_ff.\n",
        "        # ReLU activation introduces non-linearity.\n",
        "        self.dense1 = layers.Dense(d_ff, activation='relu')  # (Output dimension is d_ff)\n",
        "\n",
        "        # The second dense layer projects the dimension back from d_ff to d_model.\n",
        "        # This ensures the output dimension matches the input dimension for residual connections.\n",
        "        self.dense2 = layers.Dense(d_model)  # (Output dimension is d_model)\n",
        "\n",
        "        self.dropout = layers.Dropout(dropout_rate) # Dropout for regularization.\n",
        "\n",
        "    def call(self, x, training=False):\n",
        "        \"\"\"\n",
        "        Performs the feed-forward network operation.\n",
        "\n",
        "        Args:\n",
        "            x: Input tensor of shape [batch_size, seq_len, d_model].\n",
        "            training: Boolean indicating whether the model is in training mode (for dropout).\n",
        "\n",
        "        Returns:\n",
        "            Tensor of shape [batch_size, seq_len, d_model].\n",
        "        \"\"\"\n",
        "        x = self.dense1(x) # First linear transformation with ReLU.\n",
        "        x = self.dropout(x, training=training) # Apply dropout.\n",
        "        x = self.dense2(x) # Second linear transformation.\n",
        "        return x"
      ],
      "metadata": {
        "id": "RN9l-QGHanCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PART 5: ENCODER LAYER"
      ],
      "metadata": {
        "id": "CUTl2t2Aa5_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# PART 5: ENCODER LAYER\n",
        "# ==============================================================================\n",
        "\n",
        "class EncoderLayer(layers.Layer):\n",
        "    \"\"\"\n",
        "    Single Transformer Encoder Layer.\n",
        "\n",
        "    Each encoder layer consists of two main sub-layers:\n",
        "    1. A Multi-Head Self-Attention mechanism.\n",
        "    2. A Position-wise Feed-Forward Network.\n",
        "\n",
        "    Each sub-layer has a residual connection followed by layer normalization.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout_rate=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.mha = MultiHeadAttention(d_model, num_heads) # Multi-head self-attention sub-layer.\n",
        "        self.ffn = FeedForwardNetwork(d_model, d_ff, dropout_rate) # Position-wise feed-forward network sub-layer.\n",
        "\n",
        "        # Layer Normalization layers. `epsilon` is added for numerical stability.\n",
        "        # Layer normalization normalizes across the feature dimension, rather than batch dimension.\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)  # (LayerNormalization is used in Transformers)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = layers.Dropout(dropout_rate) # Dropout for attention output.\n",
        "        self.dropout2 = layers.Dropout(dropout_rate) # Dropout for FFN output.\n",
        "\n",
        "    def call(self, x, mask, training=False):\n",
        "        \"\"\"\n",
        "        Performs a single encoder layer operation.\n",
        "\n",
        "        Args:\n",
        "            x: Input tensor to the encoder layer, shape [batch_size, seq_len, d_model].\n",
        "            mask: Padding mask for self-attention.\n",
        "            training: Boolean indicating whether the model is in training mode.\n",
        "\n",
        "        Returns:\n",
        "            Tensor of shape [batch_size, seq_len, d_model]. The output of the encoder layer.\n",
        "        \"\"\"\n",
        "        # Multi-head self-attention sub-layer.\n",
        "        # Query, Key, and Value are all derived from the same input `x` in self-attention.\n",
        "        attn_output, _ = self.mha(x, x, x, mask)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "\n",
        "        # Add & Norm: Add residual connection and apply layer normalization.\n",
        "        # `x + attn_output` implements the residual connection, helping with gradient flow.\n",
        "        out1 = self.layernorm1(___BLANK___)  # ___BLANK___ (Add residual connection then LayerNorm)\n",
        "\n",
        "        # Feed-forward network sub-layer.\n",
        "        ffn_output = self.ffn(out1, training=training)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "\n",
        "        # Add & Norm: Add another residual connection and apply layer normalization.\n",
        "        # `out1 + ffn_output` is the second residual connection.\n",
        "        out2 = self.layernorm2(___BLANK___)  # ___BLANK___ (Add residual connection then LayerNorm)\n",
        "\n",
        "        return out2"
      ],
      "metadata": {
        "id": "tJK0h5Uea8RE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PART 6: DECODER LAYER"
      ],
      "metadata": {
        "id": "SIUjT0pIbAjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# PART 6: DECODER LAYER\n",
        "# ==============================================================================\n",
        "\n",
        "class DecoderLayer(layers.Layer):\n",
        "    \"\"\"\n",
        "    Single Transformer Decoder Layer.\n",
        "\n",
        "    Each decoder layer consists of three main sub-layers:\n",
        "    1. A Masked Multi-Head Self-Attention mechanism (to attend to preceding tokens).\n",
        "    2. A Multi-Head Cross-Attention mechanism (to attend to the encoder's output).\n",
        "    3. A Position-wise Feed-Forward Network.\n",
        "\n",
        "    Each sub-layer has a residual connection followed by layer normalization.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout_rate=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        self.mha1 = MultiHeadAttention(d_model, num_heads)  # First MHA: Masked self-attention over target sequence.\n",
        "        self.mha2 = MultiHeadAttention(d_model, num_heads)  # Second MHA: Cross-attention between encoder output and decoder output.\n",
        "        self.ffn = FeedForwardNetwork(d_model, d_ff, dropout_rate) # Position-wise feed-forward network.\n",
        "\n",
        "        # Layer Normalization layers for each sub-layer.\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3 = layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        # Dropout layers for regularization.\n",
        "        self.dropout1 = layers.Dropout(dropout_rate)\n",
        "        self.dropout2 = layers.Dropout(dropout_rate)\n",
        "        self.dropout3 = layers.Dropout(dropout_rate)\n",
        "\n",
        "    def call(self, x, encoder_output, look_ahead_mask, padding_mask, training=False):\n",
        "        \"\"\"\n",
        "        Performs a single decoder layer operation.\n",
        "\n",
        "        Args:\n",
        "            x: Input tensor to the decoder layer, shape [batch_size, target_seq_len, d_model].\n",
        "            encoder_output: Output from the encoder, shape [batch_size, input_seq_len, d_model].\n",
        "            look_ahead_mask: Mask to prevent the decoder from attending to future target tokens.\n",
        "            padding_mask: Padding mask for the cross-attention (applied to encoder output).\n",
        "            training: Boolean indicating whether the model is in training mode.\n",
        "\n",
        "        Returns:\n",
        "            Tensor of shape [batch_size, target_seq_len, d_model]. The output of the decoder layer.\n",
        "        \"\"\"\n",
        "        # First sub-layer: Masked Multi-Head Self-Attention.\n",
        "        # Decoder attends to its own previous outputs. `look_ahead_mask` prevents cheating.\n",
        "        attn1, _ = self.mha1(x, x, x, look_ahead_mask)\n",
        "        attn1 = self.dropout1(attn1, training=training)\n",
        "        out1 = self.layernorm1(x + attn1) # Add & Norm.\n",
        "\n",
        "        # Second sub-layer: Multi-Head Cross-Attention.\n",
        "        # Decoder attends to the encoder's output. The query comes from the decoder (`out1`),\n",
        "        # while the key and value come from the `encoder_output`.\n",
        "        attn2, _ = self.mha2(out1, encoder_output, encoder_output, padding_mask)  # (Query=out1, Key=EncoderOutput, Value=EncoderOutput)\n",
        "        attn2 = self.dropout2(attn2, training=training)\n",
        "        out2 = self.layernorm2(out1 + attn2) # Add & Norm.\n",
        "\n",
        "        # Third sub-layer: Position-wise Feed-Forward Network.\n",
        "        ffn_output = self.ffn(out2, training=training)\n",
        "        ffn_output = self.dropout3(ffn_output, training=training)\n",
        "        out3 = self.layernorm3(out2 + ffn_output) # Add & Norm.\n",
        "\n",
        "        return out3"
      ],
      "metadata": {
        "id": "-V10giSlbDPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PART 7: ENCODER AND DECODER"
      ],
      "metadata": {
        "id": "FZo4cJZabKom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# PART 7: ENCODER AND DECODER\n",
        "# ==============================================================================\n",
        "\n",
        "class Encoder(layers.Layer):\n",
        "    \"\"\"Transformer Encoder - A stack of `num_layers` EncoderLayer instances.\"\"\"\n",
        "    def __init__(self, num_layers, d_model, num_heads, d_ff, vocab_size,\n",
        "                 max_len, dropout_rate=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = layers.Embedding(vocab_size, d_model) # Token embedding layer.\n",
        "        self.pos_encoding = get_positional_encoding(max_len, d_model) # Positional encoding matrix.\n",
        "\n",
        "        # Create a list of EncoderLayer instances.\n",
        "        self.enc_layers = [\n",
        "            EncoderLayer(d_model, num_heads, d_ff, dropout_rate)\n",
        "            for _ in range(num_layers)\n",
        "        ]\n",
        "\n",
        "        self.dropout = layers.Dropout(dropout_rate) # Dropout for embeddings and positional encodings.\n",
        "\n",
        "    def call(self, x, mask, training=False):\n",
        "        \"\"\"\n",
        "        Performs the forward pass through the Encoder.\n",
        "\n",
        "        Args:\n",
        "            x: Input sequence token IDs, shape [batch_size, seq_len].\n",
        "            mask: Padding mask for the input sequence.\n",
        "            training: Boolean indicating whether the model is in training mode.\n",
        "\n",
        "        Returns:\n",
        "            Tensor of shape [batch_size, seq_len, d_model]. The output of the encoder.\n",
        "        \"\"\"\n",
        "        seq_len = tf.shape(x)[1]\n",
        "\n",
        "        # Step 1: Token Embedding.\n",
        "        # Convert input token IDs into dense vector representations.\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        # Step 2: Scale embeddings.\n",
        "        # Multiply embeddings by sqrt(d_model) as suggested in the Transformer paper.\n",
        "        # This is to make the positional encoding relatively smaller and prevent it from dominating the embeddings.\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))  # (Scaling by sqrt of model dimension)\n",
        "\n",
        "        # Step 3: Add Positional Encoding.\n",
        "        # Combine word embeddings with positional information.\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training) # Apply dropout after adding positional encoding.\n",
        "\n",
        "        # Step 4: Pass through the stack of encoder layers.\n",
        "        for enc_layer in self.enc_layers:\n",
        "            x = enc_layer(x, mask, training=training)\n",
        "\n",
        "        return x\n",
        "\n",
        "class Decoder(layers.Layer):\n",
        "    \"\"\"Transformer Decoder - A stack of `num_layers` DecoderLayer instances.\"\"\"\n",
        "    def __init__(self, num_layers, d_model, num_heads, d_ff, vocab_size,\n",
        "                 max_len, dropout_rate=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = layers.Embedding(vocab_size, d_model) # Token embedding layer.\n",
        "        self.pos_encoding = get_positional_encoding(max_len, d_model) # Positional encoding matrix.\n",
        "\n",
        "        # Create a list of DecoderLayer instances.\n",
        "        self.dec_layers = [\n",
        "            DecoderLayer(d_model, num_heads, d_ff, dropout_rate)\n",
        "            for _ in range(num_layers)\n",
        "        ]\n",
        "\n",
        "        self.dropout = layers.Dropout(dropout_rate) # Dropout for embeddings and positional encodings.\n",
        "\n",
        "    def call(self, x, encoder_output, look_ahead_mask, padding_mask, training=False):\n",
        "        \"\"\"\n",
        "        Performs the forward pass through the Decoder.\n",
        "\n",
        "        Args:\n",
        "            x: Input tensor to the decoder layer, shape [batch_size, target_seq_len, d_model].\n",
        "            encoder_output: Output from the encoder, shape [batch_size, input_seq_len, d_model].\n",
        "            look_ahead_mask: Mask to prevent the decoder from attending to future target tokens.\n",
        "            padding_mask: Padding mask for the cross-attention (applied to encoder output).\n",
        "            training: Boolean indicating whether the model is in training mode.\n",
        "\n",
        "        Returns:\n",
        "            Tensor of shape [batch_size, target_seq_len, d_model]. The output of the decoder.\n",
        "        \"\"\"\n",
        "        seq_len = tf.shape(x)[1]\n",
        "\n",
        "        # Step 1: Token Embedding.\n",
        "        x = self.embedding(x)\n",
        "        # Step 2: Scale embeddings.\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "\n",
        "        # Step 3: Add Positional Encoding.\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training) # Apply dropout.\n",
        "\n",
        "        # Step 4: Pass through the stack of decoder layers.\n",
        "        for dec_layer in self.dec_layers:\n",
        "            x = dec_layer(x, encoder_output, look_ahead_mask, padding_mask, training=training)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "hGZv9KjcbLs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PART 8: TRANSFORMER MODEL"
      ],
      "metadata": {
        "id": "Ttp4UJbZbQBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# PART 8: TRANSFORMER MODEL\n",
        "# ==============================================================================\n",
        "\n",
        "class Transformer(keras.Model):\n",
        "    \"\"\"Complete Transformer model, combining Encoder and Decoder components.\"\"\"\n",
        "    def __init__(self, num_layers, d_model, num_heads, d_ff,\n",
        "                 input_vocab_size, target_vocab_size, max_len, dropout_rate=0.1):\n",
        "        super(Transformer, self).__init__()\n",
        "\n",
        "        # Initialize the Encoder part of the Transformer.\n",
        "        self.encoder = Encoder(num_layers, d_model, num_heads, d_ff,\n",
        "                              input_vocab_size, max_len, dropout_rate)\n",
        "\n",
        "        # Initialize the Decoder part of the Transformer.\n",
        "        self.decoder = Decoder(num_layers, d_model, num_heads, d_ff,\n",
        "                              target_vocab_size, max_len, dropout_rate)\n",
        "\n",
        "        # Final linear layer to project the decoder output to the size of the target vocabulary.\n",
        "        # This layer produces logits for each possible next token.\n",
        "        self.final_layer = layers.Dense(target_vocab_size)\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        \"\"\"\n",
        "        Performs the forward pass through the entire Transformer model.\n",
        "\n",
        "        Args:\n",
        "            inputs: A tuple containing (encoder_input, decoder_input).\n",
        "                    encoder_input: Source sequence token IDs.\n",
        "                    decoder_input: Target sequence token IDs (shifted right).\n",
        "            training: Boolean indicating whether the model is in training mode.\n",
        "\n",
        "        Returns:\n",
        "            Tensor of shape [batch_size, target_seq_len, target_vocab_size]. Logits for each target token.\n",
        "        \"\"\"\n",
        "        inp, tar = inputs # Unpack encoder input and decoder input.\n",
        "\n",
        "        # Create various masks needed for the encoder and decoder.\n",
        "        enc_padding_mask = self.create_padding_mask(inp) # Mask for encoder self-attention (hides padding in source).\n",
        "        dec_padding_mask = self.create_padding_mask(inp) # Mask for decoder cross-attention (hides padding in source).\n",
        "        look_ahead_mask = self.create_look_ahead_mask(tf.shape(tar)[1]) # Mask for decoder self-attention (hides future tokens in target).\n",
        "        dec_target_padding_mask = self.create_padding_mask(tar) # Padding mask for decoder self-attention (hides padding in target).\n",
        "\n",
        "        # Combine the look-ahead mask and the target padding mask for decoder self-attention.\n",
        "        # tf.maximum ensures that if either mask indicates a position should be masked, it will be.\n",
        "        combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)  # (Combines look-ahead and padding masks)\n",
        "\n",
        "        # Encode the source sequence.\n",
        "        # The encoder output contains context-aware representations of the input.\n",
        "        enc_output = self.encoder(inp, enc_padding_mask, training=training)\n",
        "\n",
        "        # Decode the target sequence using encoder output and masks.\n",
        "        dec_output = self.decoder(tar, enc_output, combined_mask, dec_padding_mask, training=training)\n",
        "\n",
        "        # Project the decoder's output to the vocabulary size to get final token predictions.\n",
        "        final_output = self.final_layer(dec_output)\n",
        "\n",
        "        return final_output\n",
        "\n",
        "    def create_padding_mask(self, seq):\n",
        "        \"\"\"\n",
        "        Creates a mask to hide padding tokens (zeros) in a sequence.\n",
        "        This prevents attention from being placed on non-meaningful padded elements.\n",
        "\n",
        "        Args:\n",
        "            seq: Input sequence tensor, e.g., [batch_size, seq_len].\n",
        "\n",
        "        Returns:\n",
        "            A float32 tensor of shape [batch_size, 1, 1, seq_len].\n",
        "            Masked positions (where seq is 0) will be 1, others 0.\n",
        "        \"\"\"\n",
        "        # Compare sequence elements to 0. Where `seq` is 0 (padding), the result is True.\n",
        "        # `tf.cast` converts True to 1.0 and False to 0.0.\n",
        "        seq = tf.cast(tf.math.equal(seq, 0), tf.float32)  # (We want to mask padding tokens which are 0)\n",
        "\n",
        "        # Return a tensor with dimensions suitable for broadcasting into attention logits.\n",
        "        # Shape becomes [batch_size, 1, 1, seq_len].\n",
        "        return seq[:, tf.newaxis, tf.newaxis, :]  # [batch_size, 1, 1, seq_len]\n",
        "\n",
        "    def create_look_ahead_mask(self, size):\n",
        "        \"\"\"\n",
        "        Creates a mask to prevent the decoder from attending to future tokens.\n",
        "        This ensures that predictions for a token depend only on known preceding tokens.\n",
        "\n",
        "        Args:\n",
        "            size: The sequence length for which to create the mask.\n",
        "\n",
        "        Returns:\n",
        "            A float32 tensor of shape [size, size] with 1s in the upper triangle (future positions).\n",
        "        \"\"\"\n",
        "        # Create a lower triangular matrix of ones. `tf.linalg.band_part(tf.ones((size, size)), -1, 0)` creates this.\n",
        "        # Subtracting it from a matrix of ones yields an upper triangular matrix with 1s where attention should be masked.\n",
        "        mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)  # (1 - lower triangular matrix)\n",
        "\n",
        "        return mask  # [seq_len, seq_len]"
      ],
      "metadata": {
        "id": "LIBgYFmYbRHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PART 9: TRAINING SETUP"
      ],
      "metadata": {
        "id": "RggRMgZdbYEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# PART 9: TRAINING SETUP\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"BUILDING TRANSFORMER MODEL\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Instantiate the Transformer model with defined hyperparameters.\n",
        "transformer = Transformer(\n",
        "    num_layers=NUM_LAYERS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    d_ff=D_FF,\n",
        "    input_vocab_size=input_vocab_size,\n",
        "    target_vocab_size=target_vocab_size,\n",
        "    max_len=MAX_LENGTH,\n",
        "    dropout_rate=DROPOUT_RATE\n",
        ")\n",
        "\n",
        "print(\" Transformer model created\")\n",
        "\n",
        "# Define the learning rate.\n",
        "# The original Transformer paper uses a more complex learning rate schedule with warmup,\n",
        "# but for simplicity, a fixed learning rate is used here. A lower rate is often chosen for stability.\n",
        "learning_rate = ___BLANK___  # ___BLANK___ (A fixed learning rate, typically 0.001 is used)\n",
        "\n",
        "# Adam optimizer with parameters from the Transformer paper.\n",
        "optimizer = keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "# Loss function: SparseCategoricalCrossentropy is suitable for integer labels.\n",
        "# `from_logits=True` means the model outputs raw logits (before softmax).\n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "def accuracy_function(real, pred):\n",
        "    # Get the predicted token IDs\n",
        "    predictions = tf.cast(tf.argmax(pred, axis=-1), dtype=tf.int32)\n",
        "    # Compare predicted token IDs with real token IDs\n",
        "    accuracies = tf.equal(predictions, real)\n",
        "\n",
        "    # Create a mask to ignore padding (token ID 0)\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "\n",
        "    # Apply the mask to accuracies\n",
        "    accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
        "    mask = tf.cast(mask, dtype=tf.float32)\n",
        "    accuracies = accuracies * mask\n",
        "\n",
        "    # Calculate the average accuracy, ignoring masked (padded) positions\n",
        "    return tf.reduce_sum(accuracies) / tf.reduce_sum(mask)"
      ],
      "metadata": {
        "id": "5V4scArwgsdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PART 10: TRAINING"
      ],
      "metadata": {
        "id": "0cV1I7YDgvmf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b50605cc063841ac9b01cd6fa9a21c76",
            "08adc780e3ca4aabb31f0754825c94ad",
            "a20ce2feddf5429d95901e410f6b85d2",
            "0826fe09b7bc47429a7f09b206e6377e",
            "be8ee197c7534c41b9f7b26c107dc296",
            "303252e6d9c24f9fa30909edc4613b6a",
            "31d70974549a4146a12e7885ea93f301",
            "d93cb4772f954581b5fb4501899b19e5",
            "9dac6fef19a744519d360faeb39201c8",
            "43f7f98e12b54cbc8b7f3b5cd836a58e",
            "8805129f4fad4bc78ea0167131f72e39",
            "8294523465574776ae25863531c6af08",
            "0855c338c0a444b5b1dc2765f7f234ee",
            "7f72e55c0a974e1baeceb38682c72957",
            "665d823567124cf997d9bc37e75705e0",
            "ecb451f58e5740b1abf6f390e52dc2a9",
            "6fe38042fc854686b7af8c0a60198884",
            "afeb773577224a58a3619888d5ddd116",
            "b20841ccf96c46f7953894a4888a7836",
            "137c88f8c70a4efa9e4de7758639a15a",
            "4e317f60319e476989732d575fe7caf8",
            "dd00172d7ea44d08b86e2cb4b13cf378",
            "37df4929110e4c438c7b0b18254f1729",
            "491b7c1490dc443fad55b42016d38aef",
            "a7ff82c85cf547ddb5be23cf4b007370",
            "823b48ff03e44e4993b463cc88085c9e",
            "1b0b93b0684a4125a473c75dffe3fd97",
            "db826746e166477887ba44cca7bbcf85",
            "02d71cb9ec2f4ed8bb63d21d5739f0ce",
            "0333870d8aaa48d09d510500cd9a2305",
            "bd4bb118f1be4d47a94eb4d26ca7bccc",
            "7c6a9cfad54d42ffb0fde194523d3d11",
            "59268ad9159c4ddc85f1854e6f68b9af",
            "82cd04016f8a4355a28ae951c1f0ece4",
            "20e73f412dc24f19bf4132fa01b69820",
            "b7b549ba4c3e48a69d82d8d458cd65ac",
            "d40bff67b09245d8babb0c7baadc9abf",
            "6485ade20c3846ba8c192fd333d9351d",
            "639a9882360c4307b4ea7831d437d66e",
            "7574ae3d258545d6ae8cb6ed78deb03d",
            "43f1f4bdc35a4b6fa6247ee39606cea2",
            "0eafbd28e3f148a9b34520e7e9785856",
            "7b34274cd03c4436b4e399f7694586ae",
            "fc3972bb824f4524ae15bc813a3ba5d2",
            "216dedf048084749b2a575783036b3b0",
            "fa03eec4fc014d3fa2d8d3be3ea14230",
            "4206719f071741d1997f7fd33e9c94e3",
            "56c61cc012f64e50b369c02707ddf0d5",
            "f9876432bedc412296d9b08f69f23e60",
            "1fd1decdb68549c08e28f7e8e168b5c8",
            "e7b23a96df9b4d9c865171b897b1dbd7",
            "6cbb6072df384ba8a45f5bd0ca252ee3",
            "98f8cccd362c461d8d2a0b87819e513d",
            "427f40585ffd477d8e0eeab6debc831e",
            "79ac4df44ed64e5fa956b8543463b26b",
            "b0302652db71416097c665e478da5051",
            "4c2640b77e1b43beb16fcf9b3527a241",
            "0b300c7a6e874f1597844237ce3f0c88",
            "8c1dd69f474b49de8b1119660cbbe785",
            "5fe1a22b56bc4497bf9b688bf725c22e",
            "2d0af3dbde6c4d21aaf452c511ead53a",
            "b87c1954907a451b9d3d71b661d91d05",
            "0a7f4ecc829d4ec6afe3a54d2f423185",
            "7921d26552524f748c5aa89d3cae7eb8",
            "b51c0552b1284df494799093e47b553c",
            "6e8252fca1734c71b2a2eb0a9ff9deeb",
            "6c016d092d92493b83528f055eca2c7c",
            "0889bbd014c248cb8e7d6360e31ced08",
            "2f72798f09294a3a97cd111d5338e81d",
            "9c656bbdfbaf4b52b5a00b3cbebea4d9",
            "535f9a4395b5409e8a4fd4f228c23131",
            "ca3b7249a1fe46e28a66c37e0c290656",
            "d2b19945269446b49f9f2bb53c2c8bcd",
            "3105f9a2de9d4ed181df5826de375759",
            "ea432bc160e243b88397759ed121af44",
            "9ea3755f1f7740208656a05455859a3b",
            "ca8a01121e624a4b9af1921cd206d17b",
            "1e9ae11b46b5433baaa16c52bc9f4444",
            "2b4289e94f084be39e6e176741b20f35",
            "3871e1ad59a6475ebc3977bbc42720fa",
            "5fc076227ffe4c30b6f42c392b291ebb",
            "73b0a0016c78457d8e1ff3cb79ec5a22",
            "77950a96feb54e38ad955e51a01ad7a8",
            "054affb0438c46499af24e5ed51842ad",
            "bb865f3681ea4e24ba6dc508cd1b1452",
            "d3d7179be1f344cd9a05db915ff27bea",
            "6a90441ead9a4803a62005d57d225108",
            "fc2c1787f8a7479ea704e1794534352e",
            "64dcece71a6242b799a30ebbace1338f",
            "998fc710d87340e9b0225d39246c1127",
            "5b43e15da87449dbab96bbb36afdb099",
            "aa33415b03f24ae4838aa36238e77489",
            "3b4b99437aea4828900211ef469e1302",
            "17d1fd4335f44d8593888a741fdd3f71",
            "bdbf203c52f14f5c907a6f8947a3da83",
            "45c2d9021a7a4b8eb09f4d9f72cf3279",
            "a0887ec8bec9481bb06ee68cc08b212d",
            "e407c50a60214511979b496e001134c8",
            "c71e97123bda4da1a5b2b281032d1b23",
            "43d9dd2d98f146569c42f75c82a877e0",
            "43317608d9384bfcb5b3da973f542e7e",
            "5d05ea0f25b845eda727acc7009b75ec",
            "e6ff90c8380f41d19351182cc7d4667f",
            "bcde2535eed146df9a8a54fcd107c86b",
            "c9d58cd138b04acc82e5c8deea5c9d5f",
            "64e1245f86574e1bbe58452b790764da",
            "71521ee068084066a0927bbd40fb9888",
            "f8053d8b0d364db3a374d7ed8d0de892",
            "e3803f3ff303421a803a39c619b31d7e",
            "f6dd40bdb53b4a86a50579bfb8b6f64f",
            "074d956043ea4eacae4834d25832ba55",
            "969271f5ae874743aba2650812088b95",
            "45bf74e7cf4c490b8cd5a1b209208b1a",
            "cdbb88740ed04ab783fa92cfcc7d44bf",
            "2c074b7591fc4b8e8ef4921352761730",
            "a662878a45e34e07a0f02830fc9eb8c3",
            "1f2a0646e73a4648a88eadc8c881d53e",
            "16f9d800bd104883af64491633deaba3",
            "d95297c1857846e29ee832d4d4efa34b",
            "78b86b0ec7374bb586789993f5b3263d",
            "51ffb0c7798948a0a739ae6d511ccfbf"
          ]
        },
        "id": "iCzUFl8RcU1i",
        "outputId": "e1e58b64-857c-49ef-9401-c5a2875fee68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "BUILDING TRANSFORMER MODEL\n",
            "======================================================================\n",
            " Transformer model created\n",
            "\n",
            "======================================================================\n",
            "TRAINING TRANSFORMER\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b50605cc063841ac9b01cd6fa9a21c76"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/93 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8294523465574776ae25863531c6af08"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 50/93 - Loss: 0.9991 - Accuracy: 0.3671\n",
            "\n",
            "Epoch 1/10\n",
            "Train Loss: 1.0658, Train Accuracy: 0.3593\n",
            "Val Loss: 1.0357, Val Accuracy: 0.4302\n",
            "*** New best model! (based on validation accuracy) ***\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/93 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "37df4929110e4c438c7b0b18254f1729"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 50/93 - Loss: 0.7392 - Accuracy: 0.5108\n",
            "\n",
            "Epoch 2/10\n",
            "Train Loss: 0.7267, Train Accuracy: 0.5155\n",
            "Val Loss: 0.8673, Val Accuracy: 0.4984\n",
            "*** New best model! (based on validation accuracy) ***\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/93 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82cd04016f8a4355a28ae951c1f0ece4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 50/93 - Loss: 0.5821 - Accuracy: 0.5659\n",
            "\n",
            "Epoch 3/10\n",
            "Train Loss: 0.5632, Train Accuracy: 0.5893\n",
            "Val Loss: 0.7646, Val Accuracy: 0.5543\n",
            "*** New best model! (based on validation accuracy) ***\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/93 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "216dedf048084749b2a575783036b3b0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 50/93 - Loss: 0.4320 - Accuracy: 0.6515\n",
            "\n",
            "Epoch 4/10\n",
            "Train Loss: 0.4339, Train Accuracy: 0.6562\n",
            "Val Loss: 0.7070, Val Accuracy: 0.5945\n",
            "*** New best model! (based on validation accuracy) ***\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/93 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0302652db71416097c665e478da5051"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 50/93 - Loss: 0.3170 - Accuracy: 0.7245\n",
            "\n",
            "Epoch 5/10\n",
            "Train Loss: 0.3391, Train Accuracy: 0.7108\n",
            "Val Loss: 0.6805, Val Accuracy: 0.6168\n",
            "*** New best model! (based on validation accuracy) ***\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/93 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c016d092d92493b83528f055eca2c7c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 50/93 - Loss: 0.2676 - Accuracy: 0.7679\n",
            "\n",
            "Epoch 6/10\n",
            "Train Loss: 0.2723, Train Accuracy: 0.7539\n",
            "Val Loss: 0.6490, Val Accuracy: 0.6290\n",
            "*** New best model! (based on validation accuracy) ***\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/93 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1e9ae11b46b5433baaa16c52bc9f4444"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 50/93 - Loss: 0.2195 - Accuracy: 0.7798\n",
            "\n",
            "Epoch 7/10\n",
            "Train Loss: 0.2227, Train Accuracy: 0.7819\n",
            "Val Loss: 0.6339, Val Accuracy: 0.6373\n",
            "*** New best model! (based on validation accuracy) ***\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/93 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "64dcece71a6242b799a30ebbace1338f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 50/93 - Loss: 0.1851 - Accuracy: 0.7971\n",
            "\n",
            "Epoch 8/10\n",
            "Train Loss: 0.1870, Train Accuracy: 0.8016\n",
            "Val Loss: 0.6506, Val Accuracy: 0.6409\n",
            "*** New best model! (based on validation accuracy) ***\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/93 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "43d9dd2d98f146569c42f75c82a877e0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 50/93 - Loss: 0.1530 - Accuracy: 0.8207\n",
            "\n",
            "Epoch 9/10\n",
            "Train Loss: 0.1600, Train Accuracy: 0.8206\n",
            "Val Loss: 0.6656, Val Accuracy: 0.6449\n",
            "*** New best model! (based on validation accuracy) ***\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/93 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "074d956043ea4eacae4834d25832ba55"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 50/93 - Loss: 0.1357 - Accuracy: 0.8369\n",
            "\n",
            "Epoch 10/10\n",
            "Train Loss: 0.1403, Train Accuracy: 0.8337\n",
            "Val Loss: 0.6684, Val Accuracy: 0.6501\n",
            "*** New best model! (based on validation accuracy) ***\n",
            "\n",
            "======================================================================\n",
            "RESULTS\n",
            "======================================================================\n",
            "Best Validation Loss: 0.6684\n",
            "Best Validation Accuracy: 0.6501\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# PART 10: TRAINING\n",
        "# ==============================================================================\n",
        "\n",
        "def train_step(inp, tar):\n",
        "    \"\"\"Performs a single training step, including forward pass, loss calculation, and backpropagation.\"\"\"\n",
        "    # Prepare target sequences: tar_inp for decoder input (shifted right) and tar_real for ground truth.\n",
        "    # For example, if tar = [<start>, word1, word2, <end>]\n",
        "    # then tar_inp = [<start>, word1, word2] (input to predict next word)\n",
        "    # and tar_real = [word1, word2, <end>] (the actual next words to predict)\n",
        "    tar_inp = tar[:, :-1]\n",
        "    tar_real = tar[:, 1:]\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Make predictions using the Transformer model.\n",
        "        predictions = transformer([inp, tar_inp], training=True)\n",
        "\n",
        "        # Create a mask for non-padding tokens in the real target sequence.\n",
        "        # This ensures that padding tokens do not contribute to the loss.\n",
        "        mask = tf.math.not_equal(tar_real, 0) # True where tar_real is not padding (0).\n",
        "        loss = loss_fn(tar_real, predictions, sample_weight=mask) # Apply mask as sample weights.\n",
        "        accuracy = accuracy_function(tar_real, predictions)\n",
        "\n",
        "    # Calculate gradients and apply them to update model weights.\n",
        "    gradients = tape.gradient(loss, transformer.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "\n",
        "    return loss, accuracy\n",
        "\n",
        "def evaluate_model(input_data, target_data):\n",
        "    \"\"\"Evaluates the model on validation data by calculating the average loss and accuracy.\"\"\"\n",
        "    total_loss = 0\n",
        "    total_accuracy = 0\n",
        "    num_batches = len(input_data) // BATCH_SIZE\n",
        "\n",
        "    for i in range(num_batches):\n",
        "        start_idx = i * BATCH_SIZE\n",
        "        end_idx = start_idx + BATCH_SIZE\n",
        "\n",
        "        # Extract batch of input and target data.\n",
        "        inp = input_data[start_idx:end_idx]\n",
        "        tar = target_data[start_idx:end_idx]\n",
        "\n",
        "        # Prepare target sequences for evaluation (similar to training step).\n",
        "        tar_inp = tar[:, :-1]\n",
        "        tar_real = tar[:, 1:]\n",
        "\n",
        "        # Get predictions without updating weights (training=False).\n",
        "        predictions = transformer([inp, tar_inp], training=False)\n",
        "\n",
        "        # Calculate loss, ignoring padding tokens.\n",
        "        mask = tf.math.not_equal(tar_real, 0)\n",
        "        loss = loss_fn(tar_real, predictions, sample_weight=mask)\n",
        "        accuracy = accuracy_function(tar_real, predictions)\n",
        "\n",
        "        total_loss += loss\n",
        "        total_accuracy += accuracy\n",
        "\n",
        "    return total_loss / num_batches, total_accuracy / num_batches # Return average loss and accuracy per batch.\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TRAINING TRANSFORMER\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "best_val_loss = float('inf') # Initialize best validation loss to infinity.\n",
        "best_val_accuracy = 0.0 # Initialize best validation accuracy\n",
        "\n",
        "# Main training loop.\n",
        "for epoch in tqdm(range(EPOCHS)):\n",
        "    # Shuffle training data at the beginning of each epoch to ensure batches are diverse.\n",
        "    indices = np.random.permutation(len(train_input))\n",
        "    train_input_shuffled = train_input[indices]\n",
        "    train_target_shuffled = train_target[indices]\n",
        "\n",
        "    # Training phase for the current epoch.\n",
        "    num_batches = len(train_input) // BATCH_SIZE\n",
        "    total_train_loss = 0\n",
        "    total_train_accuracy = 0\n",
        "\n",
        "    for i in tqdm(range(num_batches)):\n",
        "        start_idx = i * BATCH_SIZE\n",
        "        end_idx = start_idx + BATCH_SIZE\n",
        "\n",
        "        # Get a batch of shuffled training data.\n",
        "        inp = train_input_shuffled[start_idx:end_idx]\n",
        "        tar = train_target_shuffled[start_idx:end_idx]\n",
        "\n",
        "        # Perform one training step.\n",
        "        loss, accuracy = train_step(inp, tar)\n",
        "        total_train_loss += loss\n",
        "        total_train_accuracy += accuracy\n",
        "\n",
        "        # Print progress periodically.\n",
        "        if (i + 1) % 50 == 0:\n",
        "            print(f'  Batch {i+1}/{num_batches} - Loss: {loss:.4f} - Accuracy: {accuracy:.4f}')\n",
        "\n",
        "    # Calculate average training loss and accuracy for the epoch.\n",
        "    train_loss = total_train_loss / num_batches\n",
        "    train_accuracy = total_train_accuracy / num_batches\n",
        "\n",
        "    # Evaluate the model on the validation set.\n",
        "    val_loss, val_accuracy = evaluate_model(val_input, val_target)\n",
        "\n",
        "    print(f'\\nEpoch {epoch+1}/{EPOCHS}')\n",
        "    print(f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')\n",
        "    print(f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
        "\n",
        "    # Save the model if the validation loss improves.\n",
        "    # Using validation accuracy as the primary metric for saving the best model.\n",
        "    if val_accuracy > best_val_accuracy:\n",
        "        best_val_accuracy = val_accuracy\n",
        "        best_val_loss = val_loss # Also update best_val_loss for consistent reporting\n",
        "        print(\"*** New best model! (based on validation accuracy) ***\") # In a real scenario, you'd save model weights here.\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"RESULTS\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Best Validation Loss: {best_val_loss:.4f}\")\n",
        "print(f\"Best Validation Accuracy: {best_val_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PART 11: TRANSLATION"
      ],
      "metadata": {
        "id": "EfIXbFr-g6G4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# PART 11: TRANSLATION\n",
        "# ==============================================================================\n",
        "\n",
        "def translate_transformer(sentence):\n",
        "    \"\"\"Translate using the Transformer\"\"\"\n",
        "    sentence = preprocess_sentence(sentence)\n",
        "\n",
        "    encoder_input = input_tokenizer.texts_to_sequences([sentence])\n",
        "    encoder_input = keras.preprocessing.sequence.pad_sequences(\n",
        "        encoder_input, maxlen=MAX_LENGTH, padding='post')\n",
        "    encoder_input = tf.convert_to_tensor(encoder_input)\n",
        "\n",
        "    decoder_input = [target_tokenizer.word_index['<start>']]\n",
        "    output = tf.expand_dims(decoder_input, 0)\n",
        "\n",
        "    for _ in range(MAX_LENGTH):\n",
        "        predictions = transformer([encoder_input, output], training=False)\n",
        "        predictions = predictions[:, -1:, :]\n",
        "        predicted_id = tf.argmax(predictions, axis=-1)\n",
        "\n",
        "        if predicted_id == target_tokenizer.word_index.get('<end>', 0):\n",
        "            break\n",
        "\n",
        "        # Cast predicted_id to tf.int32 to match output's dtype before concatenation\n",
        "        output = tf.concat([output, tf.cast(predicted_id, tf.int32)], axis=-1)\n",
        "\n",
        "    result = output.numpy()[0][1:]  # Remove <start>\n",
        "    decoded = [target_tokenizer.index_word.get(i, '') for i in result]\n",
        "\n",
        "    return ' '.join([w for w in decoded if w and w != '<end>'])\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TRANSLATION EXAMPLES\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Updated test cases with ground truth for better comparison\n",
        "test_cases = [\n",
        "    {\"english\": \"I am a student.\", \"german_ground_truth\": \"ich bin ein student\"},\n",
        "    {\"english\": \"How are you?\", \"german_ground_truth\": \"wie geht es dir\"},\n",
        "    {\"english\": \"Good morning.\", \"german_ground_truth\": \"guten morgen\"},\n",
        "    {\"english\": \"Thank you.\", \"german_ground_truth\": \"danke\"},\n",
        "    {\"english\": \"Where is the station?\", \"german_ground_truth\": \"wo ist der bahnhof\"},\n",
        "    {\"english\": \"He is running.\", \"german_ground_truth\": \"er rennt\"},\n",
        "    {\"english\": \"I love you.\", \"german_ground_truth\": \"ich liebe dich\"},\n",
        "]\n",
        "\n",
        "for case in test_cases:\n",
        "    english_sentence = case[\"english\"]\n",
        "    ground_truth = case[\"german_ground_truth\"]\n",
        "    model_prediction = translate_transformer(english_sentence)\n",
        "    print(f\"\\nEnglish: {english_sentence}\")\n",
        "    print(f\"Ground Truth:   {ground_truth}\")\n",
        "    print(f\"Model Prediction: {model_prediction}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TRAINING COMPLETE!\")\n",
        "print(\"=\"*70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqJyhJz9goUz",
        "outputId": "17d5e82e-1818-476b-e3e1-16f968b8905f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "TRANSLATION EXAMPLES\n",
            "======================================================================\n",
            "\n",
            "English: I am a student.\n",
            "Ground Truth:   ich bin ein student\n",
            "Model Prediction: ich bin student\n",
            "\n",
            "English: How are you?\n",
            "Ground Truth:   wie geht es dir\n",
            "Model Prediction: wie geht es dir\n",
            "\n",
            "English: Good morning.\n",
            "Ground Truth:   guten morgen\n",
            "Model Prediction: gut macht es sich\n",
            "\n",
            "English: Thank you.\n",
            "Ground Truth:   danke\n",
            "Model Prediction: danke\n",
            "\n",
            "English: Where is the station?\n",
            "Ground Truth:   wo ist der bahnhof\n",
            "Model Prediction: wo ist die datei\n",
            "\n",
            "English: He is running.\n",
            "Ground Truth:   er rennt\n",
            "Model Prediction: er rennt\n",
            "\n",
            "English: I love you.\n",
            "Ground Truth:   ich liebe dich\n",
            "Model Prediction: ich liebe dich\n",
            "\n",
            "======================================================================\n",
            "TRAINING COMPLETE!\n",
            "======================================================================\n"
          ]
        }
      ]
    }
  ]
}